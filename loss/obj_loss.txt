2024-05-19 18:25:04,708 maskrcnn_benchmark INFO: Using 1 GPUs
2024-05-19 18:25:04,708 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=False, local_rank=0, opts=['SOLVER.PRE_VAL', 'False', 'MODEL.ROI_RELATION_HEAD.LAMBDA_', '0.01', 'MODEL.ROI_RELATION_HEAD.PRUNE_RATE', '0.85', 'MODEL.ROI_RELATION_HEAD.PREDICT_USE_BIAS', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'NPredictor101', 'SOLVER.IMS_PER_BATCH', '16', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '16000', 'SOLVER.BASE_LR', '0.001', 'SOLVER.SCHEDULE.TYPE', 'WarmupMultiStepLR', 'SOLVER.STEPS', '(10000, 16000)', 'SOLVER.VAL_PERIOD', '10000', 'SOLVER.CHECKPOINT_PERIOD', '16000', 'GLOVE_DIR', '/media/n702/data1/Lxy/datasets/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', './checkpoints/NPredictor101-sgcls'], skip_test=False)
2024-05-19 18:25:04,708 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2024-05-19 18:25:05,823 maskrcnn_benchmark INFO: 
PyTorch version: 1.9.1+cu111
Is debug build: False
CUDA used to build PyTorch: 11.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.17

Python version: 3.7 (64-bit runtime)
Python platform: Linux-5.15.0-78-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: 11.1.74
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 4090
GPU 1: NVIDIA GeForce RTX 4090

Nvidia driver version: 535.54.03
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.5
[pip3] torch==1.9.1+cu111
[pip3] torchaudio==0.9.1
[pip3] torchvision==0.10.1+cu111
[conda] blas                      1.0                         mkl  
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.5           py37h6c91a56_3  
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] torch                     1.9.1+cu111              pypi_0    pypi
[conda] torchaudio                0.9.1                    pypi_0    pypi
[conda] torchvision               0.10.1+cu111             pypi_0    pypi
        Pillow (9.5.0)
2024-05-19 18:25:05,823 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2024-05-19 18:25:05,823 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: True
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
    PRE_NMS_PREDICTION_THRES: 0.3
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed  

2024-05-19 18:25:05,823 maskrcnn_benchmark INFO: Running with config:
ALPHA: 1.0
AMP_VERBOSE: False
BETA: 1.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  POST_NMS: True
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TO_TEST: None
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DETECTED_SGG_DIR: .
DTYPE: float16
GAMMA: 1.0
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: /media/n702/data1/Lxy/datasets/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
LOSS: dnorm
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    META_ARCH: Default
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DECOUPLE_INPUT: False
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GPR_TYPE: default
    L21_LOSS: None
    LABEL_SMOOTHING_LOSS: False
    LAMBDA_: 0.01
    LOSS: Default
    META_ARCH: Default
    MP_LAYER_NUM: 2
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PPR_ALPHA: -0.5
    PREDICTOR: NPredictor101
    PREDICT_USE_BIAS: False
    PREDICT_USE_VISION: True
    PRUNE_RATE: 0.85
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    SOFTTRIPLE: False
    SOFTTRIPLE_GAMMA: 0.0
    SOFTTRIPLE_K: 1
    SOFTTRIPLE_LAMBDA: 0.0
    SOFTTRIPLE_MARGIN: 0.0
    SOFTTRIPLE_MARGIN_INFER: False
    SOFTTRIPLE_TAU: 0.0
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./checkpoints/NPredictor101-sgcls
PATHS_CATALOG: /media/n702/data1/Lxy/T-CAR/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /media/n702/data1/Lxy/T-CAR/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 16000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 16000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupMultiStepLR
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: True
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  ESTIMATE_EVAL: False
  ESTIMATE_K: 2
  ESTIMATE_TAU: 0.1
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  LOAD_ESTIMATE: False
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    PRE_NMS_PREDICTION_THRES: 0.3
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2024-05-19 18:25:05,823 maskrcnn_benchmark INFO: Saving config into: ./checkpoints/NPredictor101-sgcls/config.yml
2024-05-19 18:25:05,831 maskrcnn_benchmark INFO: #################### prepare training ####################
2024-05-19 18:25:07,246 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2024-05-19 18:25:07,246 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2024-05-19 18:25:07,246 maskrcnn_benchmark.data.build INFO: Unable to load data statistics from: ./checkpoints/NPredictor101-sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2024-05-19 18:26:44,980 maskrcnn_benchmark.data.build INFO: finish
2024-05-19 18:26:44,980 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./checkpoints/NPredictor101-sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2024-05-19 18:26:44,980 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2024-05-19 18:26:47,185 maskrcnn_benchmark INFO: #################### end model construction ####################
2024-05-19 18:26:47,396 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2024-05-19 18:26:47,399 maskrcnn_benchmark INFO: #################### end distributed ####################
2024-05-19 18:26:47,399 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2024-05-19 18:26:47,725 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.bias                                                                                                      loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.weight                                                                                                    loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.bias                                                                                                      loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.weight                                                                                                    loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias of shape (32,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight of shape (32, 9)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias of shape (128,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight of shape (128, 32)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,759 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,760 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,761 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,762 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias of shape (2048,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight of shape (512, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight of shape (512, 200)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight of shape (512, 4608)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight of shape (512, 200)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias of shape (512,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight of shape (512, 4224)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.out_obj.bias of shape (151,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.out_obj.weight of shape (151, 512)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.weight of shape (51, 1024)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.bias of shape (4096,)
2024-05-19 18:26:47,763 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.weight of shape (4096, 1024)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.rel_compress.bias of shape (51,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.rel_compress.weight of shape (51, 4096)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                                                                                  loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                                                                                loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                                                                                  loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                                                                                loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2024-05-19 18:26:47,764 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2024-05-19 18:26:47,921 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2024-05-19 18:26:47,921 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-19 18:27:36,355 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into ./checkpoints/NPredictor101-sgcls/labels.json
2024-05-19 18:27:36,369 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-19 18:27:37,172 maskrcnn_benchmark INFO: #################### end dataloader ####################
2024-05-19 18:27:37,172 maskrcnn_benchmark INFO: Start training
2024-05-19 18:27:38,179 maskrcnn_benchmark INFO: ---Total norm nan clip coef nan-----------------
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: nan, (torch.Size([256, 1024, 3, 3]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: nan, (torch.Size([256]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: nan, (torch.Size([4096, 12544]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: nan, (torch.Size([4096]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: nan, (torch.Size([4096, 4096]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: nan, (torch.Size([4096]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: nan, (torch.Size([128, 2, 7, 7]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: nan, (torch.Size([128]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: nan, (torch.Size([128]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: inf, (torch.Size([128]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: nan, (torch.Size([256, 128, 3, 3]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: nan, (torch.Size([256]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: nan, (torch.Size([256]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: nan, (torch.Size([256]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: nan, (torch.Size([4096, 12544]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : nan, (torch.Size([4096]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: nan, (torch.Size([4096, 4096]))
2024-05-19 18:27:38,184 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : nan, (torch.Size([4096]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: nan, (torch.Size([151, 200]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: nan, (torch.Size([151, 200]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: nan, (torch.Size([32, 9]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: nan, (torch.Size([32]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: nan, (torch.Size([128, 32]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: nan, (torch.Size([128]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: nan, (torch.Size([512, 4224]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight: nan, (torch.Size([512, 200]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight: nan, (torch.Size([512, 4608]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight: nan, (torch.Size([512, 200]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: nan, (torch.Size([151, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: nan, (torch.Size([151]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,186 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,187 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,188 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,189 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,190 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: nan, (torch.Size([512, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: nan, (torch.Size([2048, 512, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: inf, (torch.Size([2048]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: nan, (torch.Size([512, 2048, 1]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: nan, (torch.Size([512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : nan, (torch.Size([1024, 512]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : nan, (torch.Size([1024]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : nan, (torch.Size([4096, 1024]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : nan, (torch.Size([4096]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : nan, (torch.Size([51, 4096]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : nan, (torch.Size([51]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : nan, (torch.Size([51, 1024]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : nan, (torch.Size([51]))
2024-05-19 18:27:38,191 maskrcnn_benchmark INFO: -------------------------------
2024-05-19 18:31:06,923 maskrcnn_benchmark INFO: eta: 4:36:10  iter: 200  loss: 38.0866 (258.3557)  obj_loss: 4.8867 (5.5706)  rel_loss: 33.0632 (252.7851)  time: 1.0205 (1.0488)  data: 0.0850 (0.1184)  lr: 0.007331  max mem: 9660
2024-05-19 18:34:31,571 maskrcnn_benchmark INFO: eta: 4:29:21  iter: 400  loss: 24.0898 (147.9168)  obj_loss: 3.4414 (4.8703)  rel_loss: 20.4101 (143.0465)  time: 1.0146 (1.0360)  data: 0.0856 (0.1057)  lr: 0.013091  max mem: 9660
2024-05-19 18:37:56,607 maskrcnn_benchmark INFO: eta: 4:24:58  iter: 600  loss: 20.1942 (110.3050)  obj_loss: 2.2441 (4.1444)  rel_loss: 17.8758 (106.1606)  time: 1.0371 (1.0324)  data: 0.0857 (0.1012)  lr: 0.016000  max mem: 9661
2024-05-19 18:41:20,207 maskrcnn_benchmark INFO: eta: 4:20:37  iter: 800  loss: 15.6161 (88.8190)  obj_loss: 1.6367 (3.5791)  rel_loss: 13.8643 (85.2399)  time: 1.0207 (1.0288)  data: 0.0870 (0.0980)  lr: 0.016000  max mem: 9839
2024-05-19 18:44:44,825 maskrcnn_benchmark INFO: eta: 4:16:54  iter: 1000  loss: 20.0919 (74.9240)  obj_loss: 1.3711 (3.1670)  rel_loss: 18.6329 (71.7570)  time: 1.0202 (1.0277)  data: 0.0867 (0.0969)  lr: 0.016000  max mem: 9839
2024-05-19 18:48:11,652 maskrcnn_benchmark INFO: eta: 4:13:45  iter: 1200  loss: 14.3946 (65.5824)  obj_loss: 1.2617 (2.8617)  rel_loss: 13.0294 (62.7208)  time: 1.0261 (1.0287)  data: 0.0869 (0.0974)  lr: 0.016000  max mem: 9966
2024-05-19 18:51:36,683 maskrcnn_benchmark INFO: eta: 4:10:12  iter: 1400  loss: 12.5243 (58.2357)  obj_loss: 1.1455 (2.6280)  rel_loss: 11.3319 (55.6077)  time: 1.0351 (1.0282)  data: 0.0899 (0.0967)  lr: 0.016000  max mem: 10516
2024-05-19 18:55:02,120 maskrcnn_benchmark INFO: eta: 4:06:44  iter: 1600  loss: 13.5929 (52.8072)  obj_loss: 1.0967 (2.4479)  rel_loss: 12.4765 (50.3593)  time: 1.0195 (1.0281)  data: 0.0871 (0.0963)  lr: 0.016000  max mem: 10516
2024-05-19 18:58:29,234 maskrcnn_benchmark INFO: eta: 4:03:30  iter: 1800  loss: 12.8862 (48.5381)  obj_loss: 1.1016 (2.2983)  rel_loss: 11.9668 (46.2399)  time: 1.0220 (1.0289)  data: 0.0865 (0.0968)  lr: 0.016000  max mem: 10516
2024-05-19 19:01:53,873 maskrcnn_benchmark INFO: eta: 3:59:56  iter: 2000  loss: 13.2256 (45.1180)  obj_loss: 1.0127 (2.1745)  rel_loss: 12.2476 (42.9435)  time: 1.0317 (1.0284)  data: 0.0877 (0.0962)  lr: 0.016000  max mem: 10516
2024-05-19 19:05:19,476 maskrcnn_benchmark INFO: eta: 3:56:30  iter: 2200  loss: 10.8386 (42.1691)  obj_loss: 1.0225 (2.0731)  rel_loss: 9.9260 (40.0960)  time: 1.0291 (1.0283)  data: 0.0880 (0.0960)  lr: 0.016000  max mem: 10516
2024-05-19 19:08:45,682 maskrcnn_benchmark INFO: eta: 3:53:08  iter: 2400  loss: 10.1432 (39.6210)  obj_loss: 1.0410 (1.9855)  rel_loss: 9.1110 (37.6354)  time: 1.0345 (1.0285)  data: 0.0849 (0.0955)  lr: 0.016000  max mem: 10516
2024-05-19 19:12:11,210 maskrcnn_benchmark INFO: eta: 3:49:41  iter: 2600  loss: 10.0438 (37.4997)  obj_loss: 0.9219 (1.9099)  rel_loss: 8.9882 (35.5899)  time: 1.0038 (1.0285)  data: 0.0863 (0.0955)  lr: 0.016000  max mem: 10516
2024-05-19 19:15:36,194 maskrcnn_benchmark INFO: eta: 3:46:12  iter: 2800  loss: 10.2472 (35.6094)  obj_loss: 0.9482 (1.8447)  rel_loss: 9.2789 (33.7647)  time: 1.0219 (1.0282)  data: 0.0880 (0.0953)  lr: 0.016000  max mem: 10516
2024-05-19 19:19:03,661 maskrcnn_benchmark INFO: eta: 3:42:54  iter: 3000  loss: 9.5024 (33.9236)  obj_loss: 0.9409 (1.7860)  rel_loss: 8.7978 (32.1376)  time: 1.0204 (1.0288)  data: 0.0851 (0.0962)  lr: 0.016000  max mem: 10516
2024-05-19 19:22:31,838 maskrcnn_benchmark INFO: eta: 3:39:38  iter: 3200  loss: 8.5882 (32.4038)  obj_loss: 0.8921 (1.7349)  rel_loss: 7.5486 (30.6689)  time: 1.0353 (1.0296)  data: 0.0868 (0.0966)  lr: 0.016000  max mem: 10516
2024-05-19 19:25:57,478 maskrcnn_benchmark INFO: eta: 3:36:11  iter: 3400  loss: 9.5143 (31.0193)  obj_loss: 0.9736 (1.6884)  rel_loss: 8.2778 (29.3309)  time: 1.0223 (1.0295)  data: 0.0887 (0.0966)  lr: 0.016000  max mem: 10516
2024-05-19 19:29:25,855 maskrcnn_benchmark INFO: eta: 3:32:54  iter: 3600  loss: 8.5238 (29.8233)  obj_loss: 0.9785 (1.6466)  rel_loss: 7.3484 (28.1767)  time: 1.0410 (1.0302)  data: 0.0909 (0.0972)  lr: 0.016000  max mem: 10516
2024-05-19 19:32:51,956 maskrcnn_benchmark INFO: eta: 3:29:28  iter: 3800  loss: 7.9723 (28.6835)  obj_loss: 0.9478 (1.6090)  rel_loss: 7.1070 (27.0745)  time: 1.0249 (1.0302)  data: 0.0864 (0.0975)  lr: 0.016000  max mem: 10516
2024-05-19 19:36:17,143 maskrcnn_benchmark INFO: ---Total norm 17.93267 clip coef 0.27882-----------------
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 9.93167, (torch.Size([51, 1024]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 5.02666, (torch.Size([4096, 12544]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 4.21559, (torch.Size([512, 4224]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 4.07114, (torch.Size([4096, 12544]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 3.82033, (torch.Size([4096, 4096]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight: 3.58406, (torch.Size([512, 4608]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 3.09243, (torch.Size([4096, 4096]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 2.94129, (torch.Size([151, 512]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 2.50047, (torch.Size([512, 512]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 2.46821, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 2.29850, (torch.Size([512, 512]))
2024-05-19 19:36:17,177 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 2.22881, (torch.Size([256, 1024, 3, 3]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 2.19794, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 2.11548, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 2.08239, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 2.00932, (torch.Size([51, 4096]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 2.00686, (torch.Size([4096, 1024]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 1.68078, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 1.67718, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight: 1.61112, (torch.Size([512, 200]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight: 1.58723, (torch.Size([512, 200]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.41091, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 1.37585, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 1.32475, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.32376, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 1.31661, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 1.29058, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.28331, (torch.Size([256, 128, 3, 3]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.18410, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 1.15196, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.11829, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.07794, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 1.07749, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 1.07749, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 1.07749, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 1.07749, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.06964, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 1.06236, (torch.Size([128, 2, 7, 7]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : 1.03387, (torch.Size([1024, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.99485, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.90065, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.89495, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.88953, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.87115, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.86776, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.84695, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.78927, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.78859, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.78759, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.77965, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.76157, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.75607, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.75236, (torch.Size([512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.74800, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.74623, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.74132, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.73118, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.71576, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.71186, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.71160, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.71043, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.69683, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.69364, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.67192, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.66417, (torch.Size([512, 512]))
2024-05-19 19:36:17,178 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.66006, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.65558, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.65453, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.65171, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.65037, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.64988, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.64123, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.64008, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.63334, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.62844, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.62810, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.62081, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.62040, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.61605, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.60880, (torch.Size([512, 2048, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.60425, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.60003, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.58832, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.58552, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.58310, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.58103, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.57172, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.56312, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.54283, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.52301, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.51977, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.51551, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.50985, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.50627, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.50351, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.50240, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.50033, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.49812, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.49201, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.48855, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.48487, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.48344, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.47382, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.46772, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.46674, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.46654, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.46203, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.46104, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.45665, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.45494, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.45098, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.44479, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.44270, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.43839, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.43573, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.43395, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.41804, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.41751, (torch.Size([512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.40929, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.40364, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.40100, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.39572, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.39427, (torch.Size([512, 512]))
2024-05-19 19:36:17,179 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.38138, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.37731, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.37517, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.36852, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.36105, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.35109, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.35067, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.34518, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.34318, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.33873, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.33264, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.33155, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.33003, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.32835, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.32788, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.32547, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.31881, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.31680, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.31222, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.31122, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias: 0.30892, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.30812, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.30634, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.30040, (torch.Size([2048, 512, 1]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.29279, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.28983, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.28503, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.28291, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias: 0.28196, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.26964, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.26258, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.24120, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.23141, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.22679, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.21946, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.21837, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.21544, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20872, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20869, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20683, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.20452, (torch.Size([51]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.20452, (torch.Size([51]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : 0.20123, (torch.Size([1024]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20054, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.19967, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.19724, (torch.Size([128]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.19003, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.18768, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.17643, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.17362, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.17338, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.16996, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.16631, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.16607, (torch.Size([151, 200]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.16511, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.16447, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.14484, (torch.Size([512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.13093, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.12593, (torch.Size([512, 512]))
2024-05-19 19:36:17,180 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.12529, (torch.Size([4096]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.11421, (torch.Size([151, 200]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.09808, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.09200, (torch.Size([512, 512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.09117, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.09077, (torch.Size([512, 512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.08440, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.08197, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.08197, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.07942, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.07942, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.07901, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.07854, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.07500, (torch.Size([151]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.07254, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.07071, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.06896, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.06773, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.06501, (torch.Size([256]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.06497, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.06082, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05926, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05858, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05622, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05553, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05509, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05462, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05462, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05461, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05461, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias: 0.05394, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05351, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05340, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.05322, (torch.Size([512, 512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05319, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05312, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05297, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05288, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05276, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05263, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05251, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05248, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.05238, (torch.Size([2048]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05221, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.05177, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05174, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05132, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05132, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05132, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05132, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.05082, (torch.Size([512, 512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05065, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05014, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05004, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04988, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04982, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04982, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04960, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04958, (torch.Size([512]))
2024-05-19 19:36:17,181 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04946, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.04898, (torch.Size([4096]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04888, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04884, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04868, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04859, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04859, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04833, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04773, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04753, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04731, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04727, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04704, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04683, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04653, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04634, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04612, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.04606, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.04558, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04547, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.04482, (torch.Size([128]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04435, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04424, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04417, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04415, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.04396, (torch.Size([4096]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04370, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04356, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04332, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04315, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04315, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04300, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04290, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04237, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04222, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04206, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04206, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04194, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04192, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.04154, (torch.Size([256]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04124, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04034, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04018, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04003, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03944, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03936, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03935, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03909, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03902, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03886, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03884, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03869, (torch.Size([512]))
2024-05-19 19:36:17,182 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03857, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.03844, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03839, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03823, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03784, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03782, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03692, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03688, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.03686, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03677, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03666, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03623, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.03617, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03614, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.03604, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.03594, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.03571, (torch.Size([4096]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.03408, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.03370, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.03296, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.03027, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02987, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02898, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02892, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02888, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02799, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.02627, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02578, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02485, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.02473, (torch.Size([512, 512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.02414, (torch.Size([128]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02350, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02342, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02332, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02273, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.02184, (torch.Size([4096]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02184, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.02145, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02127, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.02119, (torch.Size([256]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02105, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02061, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02054, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02035, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01993, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01981, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01914, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01893, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.01838, (torch.Size([256]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01827, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01818, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01801, (torch.Size([2048]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01792, (torch.Size([512]))
2024-05-19 19:36:17,183 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01768, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01762, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01750, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01728, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01711, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01707, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01667, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01657, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01654, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01629, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01625, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01622, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01608, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01564, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01562, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01543, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01539, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01516, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01513, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01506, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01492, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01460, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01446, (torch.Size([2048]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01439, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01424, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01417, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01416, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01363, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01336, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01334, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01310, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01243, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01198, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.01093, (torch.Size([128, 32]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01052, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01050, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01049, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.01041, (torch.Size([128]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01024, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00974, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00962, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00886, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00869, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00821, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00821, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00807, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00650, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00646, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00643, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00527, (torch.Size([32, 9]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00511, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00497, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00341, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00339, (torch.Size([32]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00218, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00157, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,184 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 19:36:17,185 maskrcnn_benchmark INFO: -------------------------------
2024-05-19 19:36:17,193 maskrcnn_benchmark INFO: eta: 3:26:00  iter: 4000  loss: 7.6312 (27.6453)  obj_loss: 0.9258 (1.5739)  rel_loss: 6.7048 (26.0715)  time: 1.0274 (1.0300)  data: 0.0868 (0.0971)  lr: 0.016000  max mem: 10516
2024-05-19 19:39:41,957 maskrcnn_benchmark INFO: eta: 3:22:30  iter: 4200  loss: 7.5052 (26.7164)  obj_loss: 0.9824 (1.5426)  rel_loss: 6.4752 (25.1738)  time: 1.0343 (1.0297)  data: 0.0856 (0.0967)  lr: 0.016000  max mem: 10516
2024-05-19 19:43:09,917 maskrcnn_benchmark INFO: eta: 3:19:09  iter: 4400  loss: 6.8745 (25.8307)  obj_loss: 0.8667 (1.5137)  rel_loss: 6.0548 (24.3170)  time: 1.0282 (1.0302)  data: 0.0863 (0.0971)  lr: 0.016000  max mem: 10516
2024-05-19 19:46:37,442 maskrcnn_benchmark INFO: eta: 3:15:47  iter: 4600  loss: 7.1279 (25.0799)  obj_loss: 0.8760 (1.4873)  rel_loss: 6.2910 (23.5926)  time: 1.0198 (1.0305)  data: 0.0888 (0.0974)  lr: 0.016000  max mem: 10516
2024-05-19 19:50:01,918 maskrcnn_benchmark INFO: eta: 3:12:17  iter: 4800  loss: 6.9981 (24.3344)  obj_loss: 0.9238 (1.4634)  rel_loss: 6.1669 (22.8709)  time: 1.0329 (1.0302)  data: 0.0870 (0.0972)  lr: 0.016000  max mem: 10516
2024-05-19 19:53:27,626 maskrcnn_benchmark INFO: eta: 3:08:50  iter: 5000  loss: 6.7746 (23.6415)  obj_loss: 0.9326 (1.4413)  rel_loss: 5.8468 (22.2002)  time: 1.0288 (1.0301)  data: 0.0853 (0.0972)  lr: 0.016000  max mem: 10516
2024-05-19 19:56:51,801 maskrcnn_benchmark INFO: eta: 3:05:21  iter: 5200  loss: 6.5456 (22.9977)  obj_loss: 0.8262 (1.4205)  rel_loss: 5.6016 (21.5772)  time: 1.0301 (1.0297)  data: 0.0855 (0.0969)  lr: 0.016000  max mem: 10516
2024-05-19 20:00:16,811 maskrcnn_benchmark INFO: eta: 3:01:53  iter: 5400  loss: 6.6644 (22.4166)  obj_loss: 0.9126 (1.4005)  rel_loss: 5.7701 (21.0161)  time: 1.0398 (1.0296)  data: 0.0875 (0.0967)  lr: 0.016000  max mem: 10516
2024-05-19 20:03:44,056 maskrcnn_benchmark INFO: eta: 2:58:29  iter: 5600  loss: 6.8360 (21.8742)  obj_loss: 0.8789 (1.3818)  rel_loss: 6.0431 (20.4924)  time: 1.0189 (1.0298)  data: 0.0894 (0.0969)  lr: 0.016000  max mem: 10516
2024-05-19 20:07:09,203 maskrcnn_benchmark INFO: eta: 2:55:02  iter: 5800  loss: 6.8196 (21.3549)  obj_loss: 0.8550 (1.3646)  rel_loss: 5.7854 (19.9903)  time: 1.0374 (1.0297)  data: 0.0871 (0.0968)  lr: 0.016000  max mem: 10516
2024-05-19 20:10:33,437 maskrcnn_benchmark INFO: eta: 2:51:33  iter: 6000  loss: 6.1868 (20.8620)  obj_loss: 0.8525 (1.3482)  rel_loss: 5.2706 (19.5138)  time: 1.0274 (1.0294)  data: 0.0854 (0.0966)  lr: 0.016000  max mem: 10516
2024-05-19 20:13:57,630 maskrcnn_benchmark INFO: eta: 2:48:05  iter: 6200  loss: 7.2424 (20.4227)  obj_loss: 0.8730 (1.3328)  rel_loss: 6.4250 (19.0899)  time: 1.0282 (1.0291)  data: 0.0858 (0.0964)  lr: 0.016000  max mem: 10516
2024-05-19 20:17:22,931 maskrcnn_benchmark INFO: eta: 2:44:38  iter: 6400  loss: 5.9036 (20.0051)  obj_loss: 0.8110 (1.3181)  rel_loss: 5.1536 (18.6870)  time: 1.0283 (1.0290)  data: 0.0889 (0.0963)  lr: 0.016000  max mem: 10516
2024-05-19 20:20:49,703 maskrcnn_benchmark INFO: eta: 2:41:14  iter: 6600  loss: 6.5294 (19.6132)  obj_loss: 0.8511 (1.3038)  rel_loss: 5.4811 (18.3093)  time: 1.0353 (1.0292)  data: 0.0865 (0.0963)  lr: 0.016000  max mem: 10516
2024-05-19 20:24:14,035 maskrcnn_benchmark INFO: eta: 2:37:46  iter: 6800  loss: 6.2806 (19.2372)  obj_loss: 0.8994 (1.2912)  rel_loss: 5.4520 (17.9460)  time: 1.0287 (1.0290)  data: 0.0888 (0.0961)  lr: 0.016000  max mem: 10516
2024-05-19 20:27:38,930 maskrcnn_benchmark INFO: eta: 2:34:19  iter: 7000  loss: 6.2330 (18.8744)  obj_loss: 0.8574 (1.2783)  rel_loss: 5.4220 (17.5961)  time: 1.0400 (1.0288)  data: 0.0886 (0.0959)  lr: 0.016000  max mem: 10516
2024-05-19 20:31:06,476 maskrcnn_benchmark INFO: eta: 2:30:55  iter: 7200  loss: 6.3706 (18.5306)  obj_loss: 0.8662 (1.2667)  rel_loss: 5.5151 (17.2639)  time: 1.0265 (1.0291)  data: 0.0888 (0.0960)  lr: 0.016000  max mem: 10516
2024-05-19 20:34:31,680 maskrcnn_benchmark INFO: eta: 2:27:29  iter: 7400  loss: 6.5041 (18.2109)  obj_loss: 0.7788 (1.2543)  rel_loss: 5.6611 (16.9566)  time: 1.0301 (1.0290)  data: 0.0865 (0.0959)  lr: 0.016000  max mem: 10516
2024-05-19 20:37:57,859 maskrcnn_benchmark INFO: eta: 2:24:03  iter: 7600  loss: 6.2591 (17.9008)  obj_loss: 0.7935 (1.2425)  rel_loss: 5.4164 (16.6583)  time: 1.0175 (1.0290)  data: 0.0856 (0.0960)  lr: 0.016000  max mem: 10516
2024-05-19 20:41:23,450 maskrcnn_benchmark INFO: eta: 2:20:37  iter: 7800  loss: 6.0590 (17.6044)  obj_loss: 0.8457 (1.2314)  rel_loss: 5.3058 (16.3729)  time: 1.0201 (1.0290)  data: 0.0852 (0.0960)  lr: 0.016000  max mem: 10516
2024-05-19 20:44:48,629 maskrcnn_benchmark INFO: ---Total norm 24.96284 clip coef 0.20030-----------------
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 14.92556, (torch.Size([51, 1024]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 6.66043, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 4.98188, (torch.Size([4096, 12544]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 4.83919, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 4.56108, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 4.55951, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 4.51525, (torch.Size([4096, 12544]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 3.82673, (torch.Size([4096, 4096]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 3.53776, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 3.49691, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 3.49691, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 3.49691, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 3.49691, (torch.Size([512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 3.48678, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 3.41348, (torch.Size([4096, 4096]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 3.36101, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 3.23986, (torch.Size([51, 4096]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 3.18329, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight: 3.11149, (torch.Size([512, 4608]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : 3.07962, (torch.Size([1024, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 2.90655, (torch.Size([512, 4224]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight: 2.86659, (torch.Size([512, 200]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 2.58398, (torch.Size([4096, 1024]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 2.49383, (torch.Size([256, 1024, 3, 3]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.81544, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.74597, (torch.Size([512, 512]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.74265, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,661 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.65015, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 1.58786, (torch.Size([151, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.44250, (torch.Size([256, 128, 3, 3]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight: 1.41450, (torch.Size([512, 200]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.39544, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 1.32919, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 1.19670, (torch.Size([128, 2, 7, 7]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 1.14878, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 1.12746, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 1.12061, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 1.10098, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : 1.08494, (torch.Size([1024]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.07590, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 1.06597, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 1.04681, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 1.01388, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 1.00074, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.98591, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.98552, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.91342, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.87995, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.86383, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.82000, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.81210, (torch.Size([51]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.81210, (torch.Size([51]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.79580, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias: 0.75608, (torch.Size([512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.72537, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.69574, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.63740, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.63698, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.63486, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.62661, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.62327, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.61947, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.61512, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.61148, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.60899, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.59076, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.59045, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.58133, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.58123, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.57497, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.56650, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.55752, (torch.Size([512, 512]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.55744, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,662 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.55182, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.54753, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.54636, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.53784, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.53583, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.52920, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.52102, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.51818, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.51714, (torch.Size([512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.50608, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.50568, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.50419, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.49947, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.49736, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.49458, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.48670, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.48575, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.48560, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.47774, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.47532, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.47517, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.46534, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.46468, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.45502, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.45446, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.45006, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.44766, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.44652, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.44578, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.44557, (torch.Size([512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.44162, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.43710, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.43321, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.42779, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.42623, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.41817, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.41263, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.40692, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.40246, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.40135, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.40084, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.39463, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.39229, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.39200, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.39068, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.38044, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.37884, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.37043, (torch.Size([151, 200]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.36398, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.34952, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.34647, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.33726, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.32811, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.32619, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.32021, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.31994, (torch.Size([512, 512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.31772, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias: 0.31505, (torch.Size([512]))
2024-05-19 20:44:48,663 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.31361, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.31360, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.31150, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.30710, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.30397, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.30384, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.29723, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.29329, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.29215, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.28090, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.27754, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.27610, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.27302, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.27233, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.27120, (torch.Size([512, 2048, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.26350, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.26285, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.26220, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.26017, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.25736, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.25617, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.23448, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.23237, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.23187, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.22973, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.22918, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.22585, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.22219, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.22121, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.21854, (torch.Size([128]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.21787, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.21495, (torch.Size([256]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.21435, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.21172, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.21097, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.21061, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.21041, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.20935, (torch.Size([2048, 512, 1]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20916, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20811, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.20375, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20126, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.19462, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.19460, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.19291, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.18340, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.18340, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.18030, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.17452, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.17452, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.17437, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.17214, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.16949, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.16701, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.16455, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.15698, (torch.Size([512, 512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.14905, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.14466, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.14211, (torch.Size([512]))
2024-05-19 20:44:48,664 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.14124, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.13914, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.13734, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.13638, (torch.Size([4096]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.13544, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.12586, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.12354, (torch.Size([4096]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.12301, (torch.Size([256]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.12288, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.11942, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.11490, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.10295, (torch.Size([151, 200]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias: 0.09731, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.08021, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.07250, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.07021, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.06997, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.06963, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.06887, (torch.Size([128]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.06779, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.06701, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.06683, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.06636, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.06575, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.06447, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.06447, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.06447, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.06447, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.06437, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.06418, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.06188, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.06163, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.06075, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.06062, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.06036, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05996, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05849, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.05841, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.05631, (torch.Size([4096]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.05613, (torch.Size([2048]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05497, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.05400, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.05391, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05381, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05283, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05283, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.05267, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.05226, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.05160, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.05141, (torch.Size([151]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.05085, (torch.Size([2048]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.05075, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04927, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04927, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04884, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.04850, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.04830, (torch.Size([512, 512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04809, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04809, (torch.Size([512]))
2024-05-19 20:44:48,665 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04776, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04720, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04698, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.04690, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04685, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.04659, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04643, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04636, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04612, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04611, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04611, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04608, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04594, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04589, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04587, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04579, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04578, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04574, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04568, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04555, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04534, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04507, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04498, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04467, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04456, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04442, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04429, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04408, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04396, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04362, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04292, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04277, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04271, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.04271, (torch.Size([4096]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04269, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04262, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04248, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04193, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04193, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04187, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04169, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04145, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04121, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.04121, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04119, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.04117, (torch.Size([512, 512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.04025, (torch.Size([512, 512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04007, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03963, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03937, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03936, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03872, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03866, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03765, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03698, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03672, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03604, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03576, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03572, (torch.Size([512]))
2024-05-19 20:44:48,666 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03533, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03514, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03505, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03501, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03412, (torch.Size([128]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03212, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03196, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03143, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02946, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02946, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.02934, (torch.Size([4096]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.02904, (torch.Size([256]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02752, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02666, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.02663, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.02502, (torch.Size([256]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02400, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02365, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02364, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.02225, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02140, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.02131, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02057, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02048, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01995, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01986, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01978, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01932, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01905, (torch.Size([512, 512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01903, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01861, (torch.Size([512, 512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01844, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01831, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01816, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01806, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01720, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01669, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01664, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01660, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01643, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01625, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01622, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01615, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01612, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01611, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01557, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01556, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01535, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01517, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01515, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01496, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01488, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01478, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01468, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01466, (torch.Size([2048]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01438, (torch.Size([512, 512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01433, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01416, (torch.Size([512]))
2024-05-19 20:44:48,667 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01398, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01397, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01376, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01372, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01367, (torch.Size([512, 512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01332, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01298, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01274, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01265, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01204, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01193, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01187, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01181, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01155, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.01135, (torch.Size([128]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.01125, (torch.Size([128, 32]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01110, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01087, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01064, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01059, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00984, (torch.Size([32, 9]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00911, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00827, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00796, (torch.Size([2048]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00699, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00686, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00669, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00644, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00642, (torch.Size([32]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00621, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00531, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00492, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00391, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00292, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00134, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00107, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00001, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 20:44:48,668 maskrcnn_benchmark INFO: -------------------------------
2024-05-19 20:44:48,677 maskrcnn_benchmark INFO: eta: 2:17:11  iter: 8000  loss: 6.1401 (17.3206)  obj_loss: 0.8374 (1.2211)  rel_loss: 5.2900 (16.0996)  time: 1.0296 (1.0289)  data: 0.0870 (0.0958)  lr: 0.016000  max mem: 10516
2024-05-19 20:48:13,442 maskrcnn_benchmark INFO: eta: 2:13:44  iter: 8200  loss: 6.1704 (17.0516)  obj_loss: 0.7637 (1.2109)  rel_loss: 5.3743 (15.8407)  time: 1.0264 (1.0288)  data: 0.0884 (0.0956)  lr: 0.016000  max mem: 10516
2024-05-19 20:51:40,959 maskrcnn_benchmark INFO: eta: 2:10:20  iter: 8400  loss: 6.0796 (16.7886)  obj_loss: 0.7847 (1.2016)  rel_loss: 5.1217 (15.5870)  time: 1.0339 (1.0290)  data: 0.0863 (0.0958)  lr: 0.016000  max mem: 10516
2024-05-19 20:55:06,284 maskrcnn_benchmark INFO: eta: 2:06:54  iter: 8600  loss: 5.9089 (16.5482)  obj_loss: 0.6655 (1.1924)  rel_loss: 5.1120 (15.3558)  time: 1.0303 (1.0290)  data: 0.0865 (0.0957)  lr: 0.016000  max mem: 10516
2024-05-19 20:58:31,990 maskrcnn_benchmark INFO: eta: 2:03:28  iter: 8800  loss: 5.8247 (16.3102)  obj_loss: 0.8188 (1.1838)  rel_loss: 5.0145 (15.1264)  time: 1.0195 (1.0290)  data: 0.0838 (0.0957)  lr: 0.016000  max mem: 10516
2024-05-19 21:01:56,728 maskrcnn_benchmark INFO: eta: 2:00:01  iter: 9000  loss: 6.0721 (16.0868)  obj_loss: 0.7783 (1.1755)  rel_loss: 5.2109 (14.9113)  time: 1.0380 (1.0288)  data: 0.0869 (0.0956)  lr: 0.016000  max mem: 10516
2024-05-19 21:05:22,035 maskrcnn_benchmark INFO: eta: 1:56:35  iter: 9200  loss: 5.5340 (15.8692)  obj_loss: 0.7139 (1.1675)  rel_loss: 4.7860 (14.7017)  time: 1.0224 (1.0288)  data: 0.0869 (0.0955)  lr: 0.016000  max mem: 10516
2024-05-19 21:08:48,156 maskrcnn_benchmark INFO: eta: 1:53:10  iter: 9400  loss: 5.8572 (15.6608)  obj_loss: 0.7559 (1.1599)  rel_loss: 5.0248 (14.5009)  time: 1.0244 (1.0288)  data: 0.0860 (0.0955)  lr: 0.016000  max mem: 10516
2024-05-19 21:12:13,207 maskrcnn_benchmark INFO: eta: 1:49:44  iter: 9600  loss: 5.9163 (15.4596)  obj_loss: 0.8457 (1.1530)  rel_loss: 5.0516 (14.3066)  time: 1.0361 (1.0288)  data: 0.0864 (0.0953)  lr: 0.016000  max mem: 10516
2024-05-19 21:15:40,198 maskrcnn_benchmark INFO: eta: 1:46:19  iter: 9800  loss: 6.1075 (15.2699)  obj_loss: 0.7598 (1.1457)  rel_loss: 5.1909 (14.1241)  time: 1.0207 (1.0289)  data: 0.0901 (0.0954)  lr: 0.016000  max mem: 10516
2024-05-19 21:19:05,605 maskrcnn_benchmark INFO: eta: 1:42:53  iter: 10000  loss: 5.5000 (15.0868)  obj_loss: 0.7217 (1.1390)  rel_loss: 4.8697 (13.9478)  time: 1.0383 (1.0288)  data: 0.0835 (0.0954)  lr: 0.016000  max mem: 11243
2024-05-19 21:19:05,606 maskrcnn_benchmark INFO: Start validating
2024-05-19 21:19:05,756 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2024-05-19 21:23:46,810 maskrcnn_benchmark INFO: Total run time: 0:04:41.053660 (0.05621073203086853 s / img per device, on 1 devices)
2024-05-19 21:23:46,810 maskrcnn_benchmark INFO: Model inference time: 0:03:58.495519 (0.04769910383224487 s / img per device, on 1 devices)
2024-05-19 21:26:42,240 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5912
====================================================================================================
SGG eval:     R @ 20: 0.3671;     R @ 50: 0.3992;     R @ 100: 0.4082;  for mode=sgcls, type=Recall(Main).
SGG eval:  ng-R @ 20: 0.4145;  ng-R @ 50: 0.4820;  ng-R @ 100: 0.5188;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:    zR @ 20: 0.0962;    zR @ 50: 0.1090;    zR @ 100: 0.1218;  for mode=sgcls, type=Zero Shot Recall.
SGG eval: ng-zR @ 20: 0.1261; ng-zR @ 50: 0.1603; ng-zR @ 100: 0.2233;  for mode=sgcls, type=No Graph Constraint Zero Shot Recall.
SGG eval:    mR @ 20: 0.0724;    mR @ 50: 0.0890;    mR @ 100: 0.0972;  for mode=sgcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0425) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0837) (attached to:0.0161) (behind:0.1216) (belonging to:0.0000) (between:0.0192) (carrying:0.1952) (covered in:0.1071) (covering:0.0000) (eating:0.0714) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0074) (has:0.4814) (holding:0.3392) (in:0.1535) (in front of:0.0220) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2972) (of:0.3702) (on:0.5546) (on back of:0.0000) (over:0.0512) (painted on:0.0000) (parked on:0.2045) (part of:0.0000) (playing:0.0000) (riding:0.1443) (says:0.0000) (sitting on:0.2128) (standing on:0.1293) (to:0.0000) (under:0.1361) (using:0.0769) (walking in:0.0000) (walking on:0.2082) (watching:0.0588) (wearing:0.5021) (wears:0.0221) (with:0.1446) 
--------------------------------------------------------
SGG eval:    mR @ 20: 0.0741;    mR @ 50: 0.0930;    mR @ 100: 0.1007;  for mode=sgcls, type=Mean Micro Recall.
----------------------- Details ------------------------
(above:0.0237) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1279) (attached to:0.0151) (behind:0.1209) (belonging to:0.0000) (between:0.0263) (carrying:0.1786) (covered in:0.0833) (covering:0.0000) (eating:0.1304) (flying in:0.0000) (for:0.0270) (from:0.0000) (growing on:0.0000) (hanging from:0.0122) (has:0.5616) (holding:0.3467) (in:0.1567) (in front of:0.0210) (laying on:0.0400) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2994) (of:0.3383) (on:0.6177) (on back of:0.0000) (over:0.0485) (painted on:0.0000) (parked on:0.2052) (part of:0.0000) (playing:0.0000) (riding:0.1313) (says:0.0000) (sitting on:0.1868) (standing on:0.1350) (to:0.0000) (under:0.1480) (using:0.0952) (walking in:0.0000) (walking on:0.1555) (watching:0.1071) (wearing:0.5286) (wears:0.0192) (with:0.1485) 
--------------------------------------------------------
SGG eval: ng-mR @ 20: 0.1173; ng-mR @ 50: 0.1745; ng-mR @ 100: 0.2301;  for mode=sgcls, type=No Graph Constraint Mean Recall.
----------------------- Details ------------------------
(above:0.2481) (across:0.0556) (against:0.0526) (along:0.2308) (and:0.0000) (at:0.3877) (attached to:0.1430) (behind:0.2537) (belonging to:0.0952) (between:0.0000) (carrying:0.3816) (covered in:0.2500) (covering:0.1810) (eating:0.4048) (flying in:0.0000) (for:0.0370) (from:0.1000) (growing on:0.0000) (hanging from:0.1728) (has:0.5465) (holding:0.3903) (in:0.3842) (in front of:0.2215) (laying on:0.1667) (looking at:0.2174) (lying on:0.2222) (made of:0.0000) (mounted on:0.0435) (near:0.4404) (of:0.5573) (on:0.5952) (on back of:0.0455) (over:0.1098) (painted on:0.0000) (parked on:0.7585) (part of:0.1076) (playing:0.0000) (riding:0.4033) (says:0.0000) (sitting on:0.4019) (standing on:0.2337) (to:0.1389) (under:0.2798) (using:0.2692) (walking in:0.1538) (walking on:0.3188) (watching:0.1765) (wearing:0.5147) (wears:0.4361) (with:0.3761) 
--------------------------------------------------------
SGG eval: zs-mR @ 20: 0.0365; zs-mR @ 50: 0.0395; zs-mR @ 100: 0.0424;  for mode=sgcls, type=Zero-Shot Mean Recall.
----------------------- Details ------------------------
(above:0.0000) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.1111) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.1000) (holding:0.2500) (in:0.0000) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1429) (of:0.0000) (on:0.2917) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.2000) (standing on:0.6667) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.3571) 
--------------------------------------------------------
SGG eval:     A @ 20: 0.3220;     A @ 50: 0.3229;     A @ 100: 0.3229;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2024-05-19 21:26:42,452 maskrcnn_benchmark INFO: Validation Result: 0.4082
2024-05-19 21:30:07,967 maskrcnn_benchmark INFO: eta: 1:43:46  iter: 10200  loss: 5.1185 (14.8960)  obj_loss: 0.7158 (1.1321)  rel_loss: 4.4070 (13.7639)  time: 1.0398 (1.0736)  data: 0.0892 (0.1401)  lr: 0.001600  max mem: 11243
2024-05-19 21:33:32,642 maskrcnn_benchmark INFO: eta: 1:40:06  iter: 10400  loss: 5.1009 (14.7108)  obj_loss: 0.7734 (1.1249)  rel_loss: 4.4569 (13.5858)  time: 1.0390 (1.0726)  data: 0.0882 (0.1392)  lr: 0.001600  max mem: 11243
2024-05-19 21:45:03,740 maskrcnn_benchmark INFO: eta: 1:40:35  iter: 10600  loss: 5.2202 (14.5310)  obj_loss: 0.7070 (1.1181)  rel_loss: 4.4877 (13.4130)  time: 5.3096 (1.1176)  data: 4.3139 (0.1832)  lr: 0.001600  max mem: 11243
2024-05-19 22:03:05,494 maskrcnn_benchmark INFO: eta: 1:43:44  iter: 10800  loss: 5.3917 (14.3592)  obj_loss: 0.7734 (1.1115)  rel_loss: 4.6476 (13.2477)  time: 5.6456 (1.1971)  data: 4.6253 (0.2610)  lr: 0.001600  max mem: 11243
2024-05-19 22:21:15,244 maskrcnn_benchmark INFO: eta: 1:46:11  iter: 11000  loss: 4.7715 (14.1888)  obj_loss: 0.6060 (1.1043)  rel_loss: 4.1655 (13.0846)  time: 5.4388 (1.2744)  data: 4.4391 (0.3367)  lr: 0.001600  max mem: 11243
2024-05-19 22:28:34,268 maskrcnn_benchmark INFO: eta: 1:43:15  iter: 11200  loss: 4.6979 (14.0227)  obj_loss: 0.6606 (1.0971)  rel_loss: 3.9117 (12.9256)  time: 1.0410 (1.2908)  data: 0.0950 (0.3529)  lr: 0.001600  max mem: 11243
2024-05-19 22:32:01,603 maskrcnn_benchmark INFO: eta: 1:38:37  iter: 11400  loss: 4.9660 (13.8623)  obj_loss: 0.7017 (1.0901)  rel_loss: 4.3091 (12.7722)  time: 1.0406 (1.2864)  data: 0.0939 (0.3484)  lr: 0.001600  max mem: 11243
2024-05-19 22:35:27,965 maskrcnn_benchmark INFO: eta: 1:34:00  iter: 11600  loss: 4.7577 (13.7068)  obj_loss: 0.6538 (1.0833)  rel_loss: 4.0663 (12.6235)  time: 1.0346 (1.2820)  data: 0.0961 (0.3441)  lr: 0.001600  max mem: 11243
2024-05-19 22:38:55,695 maskrcnn_benchmark INFO: eta: 1:29:26  iter: 11800  loss: 4.8132 (13.5558)  obj_loss: 0.6729 (1.0764)  rel_loss: 4.0052 (12.4794)  time: 1.0287 (1.2778)  data: 0.0919 (0.3401)  lr: 0.001600  max mem: 11243
2024-05-19 22:42:22,346 maskrcnn_benchmark INFO: ---Total norm 9.88221 clip coef 0.50596-----------------
2024-05-19 22:42:22,378 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 4.39692, (torch.Size([4096, 12544]))
2024-05-19 22:42:22,378 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 3.71756, (torch.Size([51, 1024]))
2024-05-19 22:42:22,378 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 3.47661, (torch.Size([256, 1024, 3, 3]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 3.20628, (torch.Size([4096, 12544]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 2.76580, (torch.Size([4096, 4096]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 2.28761, (torch.Size([4096, 4096]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 1.95622, (torch.Size([512, 4224]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight: 1.57532, (torch.Size([512, 4608]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 1.49174, (torch.Size([51, 4096]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 1.34490, (torch.Size([4096, 1024]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 1.21254, (torch.Size([151, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.98639, (torch.Size([256, 128, 3, 3]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight: 0.92524, (torch.Size([512, 200]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.83555, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.81141, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.76357, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.76357, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.76357, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.76357, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight: 0.73684, (torch.Size([512, 200]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.71534, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.70569, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.63542, (torch.Size([128, 2, 7, 7]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.63457, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.54191, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.53892, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.53509, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : 0.52943, (torch.Size([1024, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.45250, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.44699, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.42888, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.40840, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.38346, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.38068, (torch.Size([512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.37603, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.37414, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.36953, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.36941, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.35916, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.35362, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.35064, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.34899, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.34662, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.34619, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.34209, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.34020, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.33841, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.33211, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.33202, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.33036, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.32073, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.31715, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.31382, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.31378, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.30498, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.29977, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.29779, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.29676, (torch.Size([512, 512]))
2024-05-19 22:42:22,379 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.29653, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.29614, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.29365, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.29233, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.28550, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.27860, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.27658, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.27355, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.27331, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.27152, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.26987, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.26847, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.26775, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.26667, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.26559, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.25677, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.25484, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.25346, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.25326, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.25100, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.24931, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.24825, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.24824, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.23854, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.23774, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.23719, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.23702, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.23448, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.23329, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.23070, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.23005, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.22997, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.22890, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.22604, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.22594, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.22472, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.22425, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.22275, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.21831, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.21744, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.21243, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.20908, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.20864, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.20808, (torch.Size([51]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.20808, (torch.Size([51]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20753, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.20532, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.20495, (torch.Size([512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.20440, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20423, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.20330, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.20184, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.20158, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : 0.20135, (torch.Size([1024]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.19991, (torch.Size([512, 512]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.19956, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,380 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.19331, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.19050, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.18937, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.18876, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.18798, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.18784, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.18748, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.18624, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.18261, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.17945, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.17902, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.17727, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias: 0.17577, (torch.Size([512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.17102, (torch.Size([151, 200]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.16697, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.16608, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.16334, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.16073, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.15866, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.15803, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.15801, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.15633, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.15602, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.15438, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.15302, (torch.Size([128]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.15199, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.15062, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.14960, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias: 0.14896, (torch.Size([512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.14872, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.14136, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.14106, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.14095, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.13842, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.13809, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.12698, (torch.Size([512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.12693, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.12658, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.12487, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.11889, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.11484, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.11380, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.11180, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.11122, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.11073, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.11072, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.10975, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.10811, (torch.Size([512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.10691, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.10637, (torch.Size([256]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.09554, (torch.Size([2048, 512, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.09525, (torch.Size([512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.09467, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.09404, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.09261, (torch.Size([4096]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.08508, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.08409, (torch.Size([512, 512]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.08268, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,381 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.08172, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.08162, (torch.Size([4096]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.08130, (torch.Size([512, 2048, 1]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.07901, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.07897, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.07727, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.06903, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.06788, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.06571, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.06551, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.06403, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.06359, (torch.Size([151, 200]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.06344, (torch.Size([256]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.06234, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.05315, (torch.Size([128]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05032, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04965, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.04682, (torch.Size([128]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04569, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04216, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.04091, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.03973, (torch.Size([151]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.03773, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.03773, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03762, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.03727, (torch.Size([4096]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.03670, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.03670, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.03630, (torch.Size([4096]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03626, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03580, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.03541, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.03414, (torch.Size([256]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03298, (torch.Size([256]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03266, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.03245, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03154, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03148, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03084, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03057, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03056, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02993, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.02972, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02950, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.02949, (torch.Size([512, 512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02932, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias: 0.02903, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02873, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02864, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02836, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02820, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02804, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02796, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02788, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02780, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02744, (torch.Size([512]))
2024-05-19 22:42:22,382 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02712, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02707, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02685, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02675, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02671, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02671, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02666, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02637, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02637, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02637, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02637, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02603, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02601, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02547, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02536, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02532, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02531, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02526, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02514, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02514, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02481, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02455, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02443, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02405, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02404, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02368, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02343, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02324, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02318, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02317, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02311, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02311, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02296, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02256, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02256, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02247, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02237, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02233, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02224, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02159, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02105, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02100, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01971, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.01961, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01935, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01928, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01889, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01870, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01870, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.01865, (torch.Size([4096]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01846, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01826, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01805, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01801, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.01797, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01793, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01784, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01783, (torch.Size([512]))
2024-05-19 22:42:22,383 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01783, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01774, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01757, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01749, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01745, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01745, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.01729, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.01716, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01713, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01700, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01697, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01677, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01623, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01623, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01601, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01599, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01589, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01576, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01567, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01552, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01544, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01543, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01532, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01528, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01512, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01502, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01491, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01451, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01447, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01423, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01410, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01336, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01273, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01224, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01169, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01155, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01134, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01047, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01034, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01023, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01014, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01005, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01000, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00999, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00994, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00992, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00981, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00974, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00970, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00952, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00919, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00913, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00910, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00910, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00909, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.00900, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00886, (torch.Size([512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00879, (torch.Size([2048]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.00865, (torch.Size([512, 512]))
2024-05-19 22:42:22,384 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00858, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00855, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00820, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00807, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00791, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00780, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00774, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00760, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00748, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00704, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00704, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00702, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00695, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00694, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00688, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00686, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00685, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00681, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00677, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00670, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00649, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00648, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00636, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00632, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00630, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00620, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00584, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00582, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00574, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00566, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00565, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.00559, (torch.Size([512, 512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00554, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.00548, (torch.Size([512, 512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00547, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00538, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00522, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00503, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00497, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00496, (torch.Size([128, 32]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00496, (torch.Size([128]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00485, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00459, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00457, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00417, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00387, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00326, (torch.Size([32, 9]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00302, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00293, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00291, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00220, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00216, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00190, (torch.Size([32]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00186, (torch.Size([2048]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00135, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00057, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00051, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,385 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 22:42:22,386 maskrcnn_benchmark INFO: -------------------------------
2024-05-19 22:42:22,394 maskrcnn_benchmark INFO: eta: 1:24:55  iter: 12000  loss: 5.0141 (13.4106)  obj_loss: 0.6631 (1.0700)  rel_loss: 4.2602 (12.3406)  time: 1.0511 (1.2738)  data: 0.0930 (0.3361)  lr: 0.001600  max mem: 11243
2024-05-19 22:45:49,211 maskrcnn_benchmark INFO: eta: 1:20:25  iter: 12200  loss: 4.6953 (13.2707)  obj_loss: 0.6860 (1.0637)  rel_loss: 4.0966 (12.2070)  time: 1.0343 (1.2698)  data: 0.0940 (0.3322)  lr: 0.001600  max mem: 11243
2024-05-19 22:49:15,629 maskrcnn_benchmark INFO: eta: 1:15:57  iter: 12400  loss: 4.6392 (13.1352)  obj_loss: 0.6138 (1.0576)  rel_loss: 4.0497 (12.0776)  time: 1.0338 (1.2660)  data: 0.0937 (0.3284)  lr: 0.001600  max mem: 11243
2024-05-19 22:52:42,033 maskrcnn_benchmark INFO: eta: 1:11:31  iter: 12600  loss: 4.4946 (13.0025)  obj_loss: 0.6860 (1.0519)  rel_loss: 3.8167 (11.9506)  time: 1.0375 (1.2623)  data: 0.0904 (0.3248)  lr: 0.001600  max mem: 11243
2024-05-19 22:56:08,541 maskrcnn_benchmark INFO: eta: 1:07:07  iter: 12800  loss: 4.8636 (12.8746)  obj_loss: 0.7246 (1.0463)  rel_loss: 4.1600 (11.8283)  time: 1.0134 (1.2587)  data: 0.0937 (0.3213)  lr: 0.001600  max mem: 11243
2024-05-19 22:59:35,295 maskrcnn_benchmark INFO: eta: 1:02:45  iter: 13000  loss: 4.8576 (12.7503)  obj_loss: 0.6680 (1.0407)  rel_loss: 4.1254 (11.7096)  time: 1.0538 (1.2552)  data: 0.0944 (0.3178)  lr: 0.001600  max mem: 11243
2024-05-19 23:03:00,738 maskrcnn_benchmark INFO: eta: 0:58:24  iter: 13200  loss: 4.6768 (12.6311)  obj_loss: 0.6729 (1.0357)  rel_loss: 4.1172 (11.5954)  time: 1.0370 (1.2518)  data: 0.0910 (0.3144)  lr: 0.001600  max mem: 11243
2024-05-19 23:06:28,756 maskrcnn_benchmark INFO: eta: 0:54:06  iter: 13400  loss: 4.6186 (12.5152)  obj_loss: 0.6743 (1.0305)  rel_loss: 4.0130 (11.4846)  time: 1.0278 (1.2486)  data: 0.0904 (0.3114)  lr: 0.001600  max mem: 11243
2024-05-19 23:09:54,305 maskrcnn_benchmark INFO: eta: 0:49:48  iter: 13600  loss: 4.8730 (12.4021)  obj_loss: 0.7080 (1.0256)  rel_loss: 4.1479 (11.3765)  time: 1.0321 (1.2454)  data: 0.0901 (0.3082)  lr: 0.001600  max mem: 11243
2024-05-19 23:13:22,363 maskrcnn_benchmark INFO: eta: 0:45:33  iter: 13800  loss: 4.7771 (12.2920)  obj_loss: 0.7354 (1.0207)  rel_loss: 3.9968 (11.2714)  time: 1.0376 (1.2424)  data: 0.0910 (0.3054)  lr: 0.001600  max mem: 11243
2024-05-19 23:16:50,493 maskrcnn_benchmark INFO: eta: 0:41:19  iter: 14000  loss: 4.8759 (12.1862)  obj_loss: 0.6938 (1.0159)  rel_loss: 4.2078 (11.1703)  time: 1.0247 (1.2395)  data: 0.0899 (0.3025)  lr: 0.001600  max mem: 11243
2024-05-19 23:20:17,059 maskrcnn_benchmark INFO: eta: 0:37:05  iter: 14200  loss: 4.9173 (12.0826)  obj_loss: 0.6973 (1.0113)  rel_loss: 4.2718 (11.0713)  time: 1.0338 (1.2366)  data: 0.0911 (0.2996)  lr: 0.001600  max mem: 11243
2024-05-19 23:23:48,683 maskrcnn_benchmark INFO: eta: 0:32:54  iter: 14400  loss: 4.8788 (11.9812)  obj_loss: 0.6519 (1.0069)  rel_loss: 4.1801 (10.9743)  time: 1.0338 (1.2341)  data: 0.0888 (0.2972)  lr: 0.001600  max mem: 11243
2024-05-19 23:27:16,690 maskrcnn_benchmark INFO: eta: 0:28:44  iter: 14600  loss: 4.4887 (11.8807)  obj_loss: 0.6328 (1.0020)  rel_loss: 3.8003 (10.8786)  time: 1.0154 (1.2315)  data: 0.0918 (0.2946)  lr: 0.001600  max mem: 11243
2024-05-19 23:30:41,229 maskrcnn_benchmark INFO: eta: 0:24:34  iter: 14800  loss: 4.5509 (11.7826)  obj_loss: 0.6191 (0.9971)  rel_loss: 3.7901 (10.7855)  time: 1.0198 (1.2287)  data: 0.0909 (0.2918)  lr: 0.001600  max mem: 11243
2024-05-19 23:34:08,029 maskrcnn_benchmark INFO: eta: 0:20:26  iter: 15000  loss: 4.4969 (11.6870)  obj_loss: 0.5923 (0.9926)  rel_loss: 3.7700 (10.6944)  time: 1.0310 (1.2261)  data: 0.0915 (0.2893)  lr: 0.001600  max mem: 11243
2024-05-19 23:37:38,127 maskrcnn_benchmark INFO: eta: 0:16:18  iter: 15200  loss: 4.6989 (11.5939)  obj_loss: 0.6641 (0.9883)  rel_loss: 3.9844 (10.6057)  time: 1.0289 (1.2237)  data: 0.0917 (0.2870)  lr: 0.001600  max mem: 11243
2024-05-19 23:41:03,797 maskrcnn_benchmark INFO: eta: 0:12:12  iter: 15400  loss: 4.7736 (11.5031)  obj_loss: 0.6782 (0.9841)  rel_loss: 4.1464 (10.5190)  time: 1.0403 (1.2212)  data: 0.0921 (0.2845)  lr: 0.001600  max mem: 11243
2024-05-19 23:44:30,364 maskrcnn_benchmark INFO: eta: 0:08:07  iter: 15600  loss: 4.3897 (11.4151)  obj_loss: 0.6592 (0.9799)  rel_loss: 3.7371 (10.4352)  time: 1.0393 (1.2188)  data: 0.0935 (0.2820)  lr: 0.001600  max mem: 11243
2024-05-19 23:47:56,462 maskrcnn_benchmark INFO: eta: 0:04:03  iter: 15800  loss: 4.5734 (11.3287)  obj_loss: 0.6685 (0.9759)  rel_loss: 3.8863 (10.3528)  time: 1.0293 (1.2164)  data: 0.0936 (0.2796)  lr: 0.001600  max mem: 11243
2024-05-19 23:51:21,280 maskrcnn_benchmark INFO: ---Total norm 12.04045 clip coef 0.41527-----------------
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 4.83314, (torch.Size([4096, 12544]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 4.79288, (torch.Size([4096, 12544]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 4.40514, (torch.Size([51, 1024]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 4.26647, (torch.Size([4096, 4096]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 3.03740, (torch.Size([4096, 4096]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 2.81391, (torch.Size([512, 4224]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 2.43201, (torch.Size([256, 1024, 3, 3]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.weight: 2.19050, (torch.Size([512, 4608]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 1.71966, (torch.Size([51, 4096]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 1.67225, (torch.Size([4096, 1024]))
2024-05-19 23:51:21,313 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 1.38145, (torch.Size([151, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.weight: 1.25596, (torch.Size([512, 200]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.95829, (torch.Size([256, 128, 3, 3]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.94205, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.92948, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.92948, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.92948, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.92948, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.92275, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.90615, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.weight: 0.89761, (torch.Size([512, 200]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.86848, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.84799, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.72325, (torch.Size([128, 2, 7, 7]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.68200, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.67073, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.63105, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.weight      : 0.61439, (torch.Size([1024, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.61371, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.61283, (torch.Size([512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.55119, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.54989, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.50332, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.48748, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.48301, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.47455, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.47126, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.46668, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.45958, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.43775, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.43433, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.43272, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.43145, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.41784, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.41587, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.40967, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.40879, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.40178, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.40016, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.39943, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.39821, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.38762, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.38320, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.38176, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.37843, (torch.Size([512, 512]))
2024-05-19 23:51:21,314 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.37287, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.37248, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.36752, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.36509, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.36199, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.35121, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.35019, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.34927, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.34692, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.34376, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.33334, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.33285, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.33054, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.32954, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.32107, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.31948, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.31827, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.30437, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.30354, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.29944, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.29905, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.29463, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.29251, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.28993, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.28980, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.28704, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.27890, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.27856, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.27823, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.27759, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.27710, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.27570, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.27194, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.27155, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.26796, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.26323, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.26089, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.26076, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.26038, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.25946, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.25931, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.25915, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.25693, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.25412, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.25395, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.25316, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.25258, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.25107, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.24844, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_textual.bias: 0.24604, (torch.Size([512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.24547, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.24374, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.24243, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.24201, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.24073, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.23618, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.23611, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.22832, (torch.Size([512, 512]))
2024-05-19 23:51:21,315 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.22771, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.22653, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.22473, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.22374, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.22247, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.22005, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.21955, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.21778, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.21702, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.21393, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.21336, (torch.Size([151, 200]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20793, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.20494, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.20470, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.20348, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.19937, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.19863, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.19606, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.19348, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.19065, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.18982, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.18947, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.18125, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_emb.bias        : 0.17997, (torch.Size([1024]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.17918, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.17902, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.17670, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.17329, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.17203, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.17199, (torch.Size([512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.16787, (torch.Size([51]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.16787, (torch.Size([51]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.16708, (torch.Size([128]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.16085, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.16064, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_textual.bias: 0.15573, (torch.Size([512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.14902, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.14647, (torch.Size([512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.14365, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.14256, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.14036, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.13697, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.13607, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.13400, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.13377, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.12937, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.12765, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.12383, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.12226, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.10855, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.10784, (torch.Size([512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.weight: 0.10510, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.10114, (torch.Size([4096]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.09807, (torch.Size([512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.09686, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.09649, (torch.Size([512, 512]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.09634, (torch.Size([256]))
2024-05-19 23:51:21,316 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.09609, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.09515, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.09438, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.09056, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.weight: 0.08576, (torch.Size([2048, 512, 1]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.08507, (torch.Size([4096]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.08016, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.weight: 0.07862, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.07685, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.07670, (torch.Size([512, 512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.07569, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.07421, (torch.Size([151, 200]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.07134, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.06991, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.06513, (torch.Size([128]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.06067, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.06031, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.05930, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05827, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05720, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05720, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.05582, (torch.Size([256]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05434, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.05434, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05345, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.05319, (torch.Size([4096]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.05294, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.05148, (torch.Size([151]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.05111, (torch.Size([128]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.05076, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.05045, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04929, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04598, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.04448, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual.bias: 0.04418, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.04269, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.04239, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04172, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.04093, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04044, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.04012, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03990, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.03967, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03922, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03837, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03802, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03788, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03758, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03716, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03659, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03632, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03580, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03541, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03537, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.03531, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.03366, (torch.Size([4096]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.03306, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.03286, (torch.Size([512]))
2024-05-19 23:51:21,317 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03281, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.03280, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.03048, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02987, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02986, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02986, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02974, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02974, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02974, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02974, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02934, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.02926, (torch.Size([256]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02899, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02894, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02883, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02879, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02868, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02847, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02817, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02806, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.02760, (torch.Size([512, 512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02744, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02721, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02721, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02697, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02688, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.02667, (torch.Size([512, 512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02662, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02660, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02637, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.weight: 0.02618, (torch.Size([512, 2048, 1]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02615, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02586, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02573, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02573, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02549, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02525, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02508, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02506, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02486, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02479, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02441, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02431, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02429, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02401, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.02333, (torch.Size([4096]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02315, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.02315, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02272, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02246, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02239, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02199, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02162, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02156, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02142, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02105, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.02094, (torch.Size([512]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02078, (torch.Size([2048]))
2024-05-19 23:51:21,318 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.02072, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.02070, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.02043, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.02017, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.02016, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.02011, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.02000, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.weight: 0.01981, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01968, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01953, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01953, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01930, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.layer_norm.bias: 0.01930, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01926, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.01894, (torch.Size([256]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01891, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01827, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01817, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01776, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01772, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01770, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01744, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01723, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.weight: 0.01712, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01700, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01697, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01682, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01661, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01648, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_2.bias: 0.01637, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01625, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.layer_norm.bias: 0.01576, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01564, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01486, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01476, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01463, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01411, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01362, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01290, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01273, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01261, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01228, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01227, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01196, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.01193, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01183, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01172, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01143, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01136, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.01121, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01116, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01107, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.01103, (torch.Size([512, 512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01099, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01097, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01095, (torch.Size([2048]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01077, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.01072, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.01043, (torch.Size([512]))
2024-05-19 23:51:21,319 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.01037, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00995, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00971, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00968, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00944, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00934, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00919, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00892, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00888, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00887, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00877, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00856, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00846, (torch.Size([128]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00821, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00808, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00798, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00780, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00776, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00756, (torch.Size([128, 32]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00754, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00724, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00720, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00709, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00702, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00693, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00690, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.fc.bias: 0.00665, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00652, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00645, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.weight: 0.00641, (torch.Size([512, 512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00637, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00637, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00636, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00635, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.weight: 0.00632, (torch.Size([512, 512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00625, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00615, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00608, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00597, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00592, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_vs.bias: 0.00581, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00580, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00543, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00448, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00440, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00397, (torch.Size([32, 9]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00383, (torch.Size([2048]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00383, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00325, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00304, (torch.Size([512]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00302, (torch.Size([32]))
2024-05-19 23:51:21,320 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00284, (torch.Size([2048]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00230, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00170, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.pos_ffn.w_1.bias: 0.00159, (torch.Size([2048]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00095, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_qs.bias: 0.00074, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_vis.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.1.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.3.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.2.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_vis.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.CA_Cell_txt.CA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.cross_module.0.SA_Cell_txt.SA_transformer_encoder.transformer_layer.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-19 23:51:21,321 maskrcnn_benchmark INFO: -------------------------------
2024-05-19 23:51:21,329 maskrcnn_benchmark INFO: eta: 0:00:00  iter: 16000  loss: 4.7319 (11.2449)  obj_loss: 0.7100 (0.9719)  rel_loss: 3.9414 (10.2730)  time: 1.0418 (1.2140)  data: 0.0916 (0.2773)  lr: 0.001600  max mem: 11243
2024-05-19 23:51:21,331 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./checkpoints/NPredictor101-sgcls/model_0016000.pth
2024-05-19 23:51:23,307 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./checkpoints/NPredictor101-sgcls/model_final.pth
2024-05-19 23:51:25,221 maskrcnn_benchmark INFO: Total training time: 5:23:48.049223 (1.2143 s / it)
2024-05-19 23:51:25,347 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-19 23:51:37,004 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2024-05-20 00:16:24,806 maskrcnn_benchmark INFO: Total run time: 0:24:47.801790 (0.05625810294471169 s / img per device, on 1 devices)
2024-05-20 00:16:24,806 maskrcnn_benchmark INFO: Model inference time: 0:21:52.931988 (0.049645768273555595 s / img per device, on 1 devices)
2024-05-20 00:30:34,193 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5897
====================================================================================================
SGG eval:     R @ 20: 0.3643;     R @ 50: 0.3994;     R @ 100: 0.4094;  for mode=sgcls, type=Recall(Main).
SGG eval:  ng-R @ 20: 0.4096;  ng-R @ 50: 0.4842;  ng-R @ 100: 0.5180;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:    zR @ 20: 0.0611;    zR @ 50: 0.0869;    zR @ 100: 0.0995;  for mode=sgcls, type=Zero Shot Recall.
SGG eval: ng-zR @ 20: 0.0739; ng-zR @ 50: 0.1281; ng-zR @ 100: 0.1665;  for mode=sgcls, type=No Graph Constraint Zero Shot Recall.
SGG eval:    mR @ 20: 0.0862;    mR @ 50: 0.1130;    mR @ 100: 0.1246;  for mode=sgcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1331) (across:0.0159) (against:0.0081) (along:0.0229) (and:0.0178) (at:0.2592) (attached to:0.0639) (behind:0.3599) (belonging to:0.0375) (between:0.0243) (carrying:0.1944) (covered in:0.1107) (covering:0.0532) (eating:0.1290) (flying in:0.0000) (for:0.0653) (from:0.0000) (growing on:0.0000) (hanging from:0.0418) (has:0.5291) (holding:0.3741) (in:0.2483) (in front of:0.1895) (laying on:0.0509) (looking at:0.0522) (lying on:0.0102) (made of:0.0000) (mounted on:0.0000) (near:0.2077) (of:0.4405) (on:0.4817) (on back of:0.0071) (over:0.0794) (painted on:0.0345) (parked on:0.1566) (part of:0.0123) (playing:0.0000) (riding:0.3133) (says:0.0000) (sitting on:0.1363) (standing on:0.0939) (to:0.0266) (under:0.1838) (using:0.1837) (walking in:0.0000) (walking on:0.1115) (watching:0.0736) (wearing:0.4927) (wears:0.0772) (with:0.1251) 
--------------------------------------------------------
SGG eval:    mR @ 20: 0.0899;    mR @ 50: 0.1198;    mR @ 100: 0.1335;  for mode=sgcls, type=Mean Micro Recall.
----------------------- Details ------------------------
(above:0.1227) (across:0.0122) (against:0.0145) (along:0.0194) (and:0.0139) (at:0.2750) (attached to:0.0656) (behind:0.3653) (belonging to:0.0404) (between:0.0185) (carrying:0.2052) (covered in:0.1224) (covering:0.0617) (eating:0.1805) (flying in:0.0000) (for:0.0650) (from:0.0000) (growing on:0.0000) (hanging from:0.0270) (has:0.5759) (holding:0.4046) (in:0.2837) (in front of:0.1920) (laying on:0.0539) (looking at:0.0458) (lying on:0.0059) (made of:0.0000) (mounted on:0.0000) (near:0.2186) (of:0.4792) (on:0.5164) (on back of:0.0056) (over:0.0754) (painted on:0.0196) (parked on:0.2397) (part of:0.0070) (playing:0.0000) (riding:0.3505) (says:0.0000) (sitting on:0.1422) (standing on:0.1079) (to:0.0261) (under:0.1754) (using:0.2262) (walking in:0.0000) (walking on:0.1235) (watching:0.0944) (wearing:0.5038) (wears:0.0671) (with:0.1260) 
--------------------------------------------------------
SGG eval: ng-mR @ 20: 0.1213; ng-mR @ 50: 0.1970; ng-mR @ 100: 0.2637;  for mode=sgcls, type=No Graph Constraint Mean Recall.
----------------------- Details ------------------------
(above:0.3856) (across:0.1190) (against:0.1210) (along:0.1437) (and:0.0414) (at:0.3612) (attached to:0.2999) (behind:0.4167) (belonging to:0.3147) (between:0.0347) (carrying:0.3715) (covered in:0.2679) (covering:0.1983) (eating:0.2404) (flying in:0.0000) (for:0.1657) (from:0.0000) (growing on:0.0310) (hanging from:0.2238) (has:0.5835) (holding:0.4200) (in:0.4283) (in front of:0.3299) (laying on:0.3471) (looking at:0.2112) (lying on:0.2902) (made of:0.0000) (mounted on:0.1708) (near:0.4003) (of:0.5671) (on:0.5511) (on back of:0.1064) (over:0.2007) (painted on:0.0751) (parked on:0.5606) (part of:0.1502) (playing:0.0000) (riding:0.4653) (says:0.0000) (sitting on:0.3678) (standing on:0.3449) (to:0.2876) (under:0.3459) (using:0.3047) (walking in:0.1127) (walking on:0.3684) (watching:0.1103) (wearing:0.5037) (wears:0.4780) (with:0.3656) 
--------------------------------------------------------
SGG eval: zs-mR @ 20: 0.0287; zs-mR @ 50: 0.0431; zs-mR @ 100: 0.0500;  for mode=sgcls, type=Zero-Shot Mean Recall.
----------------------- Details ------------------------
(above:0.1111) (across:0.0000) (against:0.0286) (along:0.0000) (and:0.0312) (at:0.0189) (attached to:0.0328) (behind:0.1597) (belonging to:0.1204) (between:0.0217) (carrying:0.0500) (covered in:0.0417) (covering:0.0333) (eating:0.0000) (flying in:0.0000) (for:0.0375) (from:0.0000) (growing on:0.0000) (hanging from:0.0417) (has:0.0996) (holding:0.0883) (in:0.0971) (in front of:0.1245) (laying on:0.1250) (looking at:0.0667) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1635) (of:0.0866) (on:0.1327) (on back of:0.0250) (over:0.0725) (painted on:0.0357) (parked on:0.0000) (part of:0.0303) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0781) (standing on:0.0938) (to:0.0263) (under:0.1454) (using:0.0000) (walking in:0.0000) (walking on:0.0588) (watching:0.0488) (wearing:0.0793) (wears:0.0000) (with:0.0940) 
--------------------------------------------------------
SGG eval:     A @ 20: 0.2829;     A @ 50: 0.2831;     A @ 100: 0.2831;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

