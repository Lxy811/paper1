2024-05-13 16:33:09,966 maskrcnn_benchmark INFO: Using 1 GPUs
2024-05-13 16:33:09,966 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=False, local_rank=0, opts=['SOLVER.PRE_VAL', 'False', 'MODEL.ROI_RELATION_HEAD.LAMBDA_', '0.01', 'MODEL.ROI_RELATION_HEAD.PRUNE_RATE', '0.85', 'MODEL.ROI_RELATION_HEAD.PREDICT_USE_BIAS', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'Predictor000', 'SOLVER.IMS_PER_BATCH', '16', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '16000', 'SOLVER.BASE_LR', '0.001', 'SOLVER.SCHEDULE.TYPE', 'WarmupMultiStepLR', 'SOLVER.STEPS', '(10000, 16000)', 'SOLVER.VAL_PERIOD', '10000', 'SOLVER.CHECKPOINT_PERIOD', '16000', 'GLOVE_DIR', '/media/n702/data1/Lxy/datasets/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', './checkpoints/Predictor000-sgcls'], skip_test=False)
2024-05-13 16:33:09,966 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2024-05-13 16:33:10,972 maskrcnn_benchmark INFO: 
PyTorch version: 1.9.1+cu111
Is debug build: False
CUDA used to build PyTorch: 11.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.17

Python version: 3.7 (64-bit runtime)
Python platform: Linux-5.15.0-78-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: 11.1.74
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 4090
GPU 1: NVIDIA GeForce RTX 4090

Nvidia driver version: 535.54.03
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.5
[pip3] torch==1.9.1+cu111
[pip3] torchaudio==0.9.1
[pip3] torchvision==0.10.1+cu111
[conda] blas                      1.0                         mkl  
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.5           py37h6c91a56_3  
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] torch                     1.9.1+cu111              pypi_0    pypi
[conda] torchaudio                0.9.1                    pypi_0    pypi
[conda] torchvision               0.10.1+cu111             pypi_0    pypi
        Pillow (9.5.0)
2024-05-13 16:33:10,973 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2024-05-13 16:33:10,973 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: True
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
    PRE_NMS_PREDICTION_THRES: 0.3
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed  

2024-05-13 16:33:10,973 maskrcnn_benchmark INFO: Running with config:
ALPHA: 1.0
AMP_VERBOSE: False
BETA: 1.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  POST_NMS: True
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TO_TEST: None
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DETECTED_SGG_DIR: .
DTYPE: float16
GAMMA: 1.0
GLOBAL_SETTING:
  BASIC_ENCODER: Hybrid-Attention
  CHOOSE_BEST_MODEL_BY_METRIC: _mean_recall
  DATASET_CHOICE: VG
  GCL_SETTING:
    GROUP_SPLIT_MODE: divide4
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0
    KNOWLEDGE_TRANSFER_MODE: KL_logit_TopDown
    NO_RELATION_PENALTY: 0.1
    NO_RELATION_RESTRAIN: True
    ZERO_LABEL_PADDING_MODE: rand_insert
  PRINT_INTERVAL: 100
  RELATION_PREDICTOR: TransLike_GCL
  USE_BIAS: True
GLOVE_DIR: /media/n702/data1/Lxy/datasets/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
LOSS: dnorm
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    META_ARCH: Default
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    DECOUPLE_INPUT: False
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    GPR_TYPE: default
    L21_LOSS: None
    LABEL_SMOOTHING_LOSS: False
    LAMBDA_: 0.01
    LOSS: Default
    META_ARCH: Default
    MP_LAYER_NUM: 2
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PPR_ALPHA: -0.5
    PREDICTOR: Predictor000
    PREDICT_USE_BIAS: False
    PREDICT_USE_VISION: True
    PRUNE_RATE: 0.85
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    SOFTTRIPLE: False
    SOFTTRIPLE_GAMMA: 0.0
    SOFTTRIPLE_K: 1
    SOFTTRIPLE_LAMBDA: 0.0
    SOFTTRIPLE_MARGIN: 0.0
    SOFTTRIPLE_MARGIN_INFER: False
    SOFTTRIPLE_TAU: 0.0
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: ./checkpoints/Predictor000-sgcls
PATHS_CATALOG: /media/n702/data1/Lxy/T-CAR/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /media/n702/data1/Lxy/T-CAR/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 16000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 16000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupMultiStepLR
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: True
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  ESTIMATE_EVAL: False
  ESTIMATE_K: 2
  ESTIMATE_TAU: 0.1
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  LOAD_ESTIMATE: False
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    PRE_NMS_PREDICTION_THRES: 0.3
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2024-05-13 16:33:10,973 maskrcnn_benchmark INFO: Saving config into: ./checkpoints/Predictor000-sgcls/config.yml
2024-05-13 16:33:10,981 maskrcnn_benchmark INFO: #################### prepare training ####################
2024-05-13 16:33:12,398 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2024-05-13 16:33:12,398 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2024-05-13 16:33:12,398 maskrcnn_benchmark.data.build INFO: Unable to load data statistics from: ./checkpoints/Predictor000-sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2024-05-13 16:34:51,069 maskrcnn_benchmark.data.build INFO: finish
2024-05-13 16:34:51,069 maskrcnn_benchmark.data.build INFO: Save data statistics to: ./checkpoints/Predictor000-sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2024-05-13 16:34:51,069 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2024-05-13 16:34:53,041 maskrcnn_benchmark INFO: #################### end model construction ####################
2024-05-13 16:34:53,187 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2024-05-13 16:34:53,190 maskrcnn_benchmark INFO: #################### end distributed ####################
2024-05-13 16:34:53,190 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /media/n702/data1/Lxy/datasets/vg/pretrained_faster_rcnn/model_final.pth
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.box_feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
2024-05-13 16:34:53,515 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
2024-05-13 16:34:53,516 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
2024-05-13 16:34:53,516 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
2024-05-13 16:34:53,516 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2024-05-13 16:34:53,516 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2024-05-13 16:34:53,536 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.bias                                                loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2024-05-13 16:34:53,536 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.weight                                              loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2024-05-13 16:34:53,536 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.bias                                                loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2024-05-13 16:34:53,536 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.weight                                              loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias of shape (32,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight of shape (32, 9)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias of shape (128,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight of shape (128, 32)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,537 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias of shape (2048,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight of shape (2048, 512, 1)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight of shape (512, 2048, 1)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight of shape (512, 4224)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight of shape (512, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias of shape (1024,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight of shape (1024, 4608)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias of shape (512,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight of shape (512, 4224)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.out_obj.bias of shape (151,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.out_obj.weight of shape (151, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias of shape (64,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight of shape (64, 21)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias of shape (128,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight of shape (128, 64)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.ctx_compress.weight of shape (51, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.bias of shape (4096,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.post_cat.weight of shape (4096, 512)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.rel_compress.bias of shape (51,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.predictor.rel_compress.weight of shape (51, 4096)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                            loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                          loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2024-05-13 16:34:53,538 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                            loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                          loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2024-05-13 16:34:53,539 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2024-05-13 16:34:53,671 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2024-05-13 16:34:53,671 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-13 16:35:41,405 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into ./checkpoints/Predictor000-sgcls/labels.json
2024-05-13 16:35:41,420 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-13 16:35:42,219 maskrcnn_benchmark INFO: #################### end dataloader ####################
2024-05-13 16:35:42,219 maskrcnn_benchmark INFO: Start training
2024-05-13 16:35:43,324 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias: inf, (torch.Size([512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight: inf, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias: inf, (torch.Size([512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias: inf, (torch.Size([512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight: inf, (torch.Size([512, 4224]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias: inf, (torch.Size([512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias: inf, (torch.Size([512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : inf, (torch.Size([51, 4096]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : inf, (torch.Size([51, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight: 2772319.50000, (torch.Size([1024, 4608]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 1891477.62500, (torch.Size([512, 4224]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight: 1693437.00000, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight: 1530411.12500, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight: 1461947.87500, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight: 1374874.50000, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight: 1366702.37500, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight: 1115044.12500, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight: 1049363.62500, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight: 619697.12500, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight: 606207.00000, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight: 397544.96875, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight: 396080.84375, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight: 378898.28125, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight: 372681.68750, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight: 366810.87500, (torch.Size([512, 2048, 1]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight: 333793.46875, (torch.Size([512, 512]))
2024-05-13 16:35:43,332 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 316464.06250, (torch.Size([4096, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight: 315331.34375, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight: 310654.40625, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight: 276756.65625, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias: 257162.81250, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight: 248492.23438, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight: 246551.64062, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight: 215322.53125, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 189184.89062, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 173576.81250, (torch.Size([151, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight: 155756.15625, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias: 147799.89062, (torch.Size([1024]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight: 141382.98438, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight: 132860.00000, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight: 131104.89062, (torch.Size([2048, 512, 1]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias: 106510.21094, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias: 105797.86719, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias: 95252.09375, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias: 93637.04688, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias: 91308.24219, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias: 89003.80469, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias: 87478.39062, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias: 85493.03906, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight: 78198.68750, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight: 77350.35156, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight: 75773.04688, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight: 75564.53125, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 65244.31641, (torch.Size([51]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 65244.31641, (torch.Size([51]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias: 54901.16016, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias: 53763.09375, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight: 42172.26953, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight: 40616.61719, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias: 32480.11719, (torch.Size([2048]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias: 31627.18164, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight: 30955.60547, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias: 30843.67383, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias: 30738.01953, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias: 30432.68945, (torch.Size([2048]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight: 28646.18945, (torch.Size([512, 512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias: 27962.35547, (torch.Size([512]))
2024-05-13 16:35:43,333 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias: 27952.73633, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias: 27675.43945, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias: 27571.25586, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias: 27280.31445, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias: 27148.77539, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias: 26862.08008, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias: 26432.39648, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight: 26340.10938, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias: 25824.99805, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight: 25435.07812, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight: 20370.41211, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight: 20290.42969, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias: 19079.97070, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight: 19016.25977, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias: 18814.16016, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight: 18201.64648, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight: 17678.32227, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias: 17514.20898, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight: 17433.39062, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias: 17420.70312, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight: 17393.89062, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias: 17114.82812, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight: 16869.75195, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight: 16858.30273, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias: 16664.21289, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight: 16280.48242, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 15869.57520, (torch.Size([4096]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias: 9736.79590, (torch.Size([2048]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias: 9355.56348, (torch.Size([2048]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 8942.93848, (torch.Size([151]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias: 8795.15723, (torch.Size([2048]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias: 8551.88867, (torch.Size([2048]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight: 3646.64307, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight: 3643.76587, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias: 2515.98096, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias: 1477.30786, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias: 1349.88586, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias: 1236.92810, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias: 808.58643, (torch.Size([512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight: 320.90677, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight: 318.87216, (torch.Size([512, 512]))
2024-05-13 16:35:43,334 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias: 242.37274, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 35.75216, (torch.Size([4096, 4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 35.26081, (torch.Size([4096, 12544]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight: 16.34989, (torch.Size([512, 512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 16.02081, (torch.Size([4096, 4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight: 15.16324, (torch.Size([512, 512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 10.54273, (torch.Size([4096, 12544]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 7.52041, (torch.Size([256, 1024, 3, 3]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias: 4.94511, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 3.55302, (torch.Size([256, 128, 3, 3]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight: 1.13176, (torch.Size([128, 64]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.84012, (torch.Size([128, 2, 7, 7]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias: 0.57664, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight: 0.43090, (torch.Size([64, 21]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.42465, (torch.Size([4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias: 0.40707, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.38459, (torch.Size([4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias: 0.37777, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.26547, (torch.Size([256]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias: 0.24455, (torch.Size([128]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.23897, (torch.Size([128, 32]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias: 0.23865, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.21451, (torch.Size([128]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.17968, (torch.Size([4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias: 0.15736, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.14656, (torch.Size([128]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.14340, (torch.Size([256]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.09358, (torch.Size([4096]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias: 0.08810, (torch.Size([64]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.08034, (torch.Size([32, 9]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.06546, (torch.Size([32]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.06464, (torch.Size([256]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.06382, (torch.Size([256]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.05516, (torch.Size([128]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.05279, (torch.Size([128]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias: 0.01592, (torch.Size([512]))
2024-05-13 16:35:43,335 maskrcnn_benchmark INFO: -------------------------------
2024-05-13 16:39:02,507 maskrcnn_benchmark INFO: eta: 4:23:42  iter: 200  loss: 2.2430 (3.6917)  loss_rel: 0.1870 (0.4097)  loss_refine_obj: 2.0406 (3.2820)  time: 0.9871 (1.0014)  data: 0.0843 (0.0977)  lr: 0.007331  max mem: 10464
2024-05-13 16:42:22,828 maskrcnn_benchmark INFO: eta: 4:20:23  iter: 400  loss: 1.4010 (2.7049)  loss_rel: 0.1655 (0.2981)  loss_refine_obj: 1.2207 (2.4067)  time: 0.9884 (1.0015)  data: 0.0860 (0.1000)  lr: 0.013091  max mem: 10540
2024-05-13 16:45:41,989 maskrcnn_benchmark INFO: eta: 4:16:34  iter: 600  loss: 1.3590 (2.2645)  loss_rel: 0.1695 (0.2566)  loss_refine_obj: 1.1744 (2.0079)  time: 0.9757 (0.9996)  data: 0.0873 (0.0993)  lr: 0.016000  max mem: 10540
2024-05-13 16:48:58,960 maskrcnn_benchmark INFO: eta: 4:12:18  iter: 800  loss: 1.2536 (2.0220)  loss_rel: 0.1572 (0.2339)  loss_refine_obj: 1.0419 (1.7881)  time: 0.9696 (0.9959)  data: 0.0837 (0.0964)  lr: 0.016000  max mem: 10540
2024-05-13 16:52:16,252 maskrcnn_benchmark INFO: eta: 4:08:30  iter: 1000  loss: 1.2306 (1.8694)  loss_rel: 0.1474 (0.2188)  loss_refine_obj: 1.0841 (1.6506)  time: 0.9977 (0.9940)  data: 0.0845 (0.0946)  lr: 0.016000  max mem: 10540
2024-05-13 16:55:33,948 maskrcnn_benchmark INFO: eta: 4:04:57  iter: 1200  loss: 1.2018 (1.7603)  loss_rel: 0.1545 (0.2079)  loss_refine_obj: 1.0263 (1.5524)  time: 0.9849 (0.9931)  data: 0.0850 (0.0935)  lr: 0.016000  max mem: 10540
2024-05-13 16:58:51,780 maskrcnn_benchmark INFO: eta: 4:01:31  iter: 1400  loss: 1.1847 (1.6755)  loss_rel: 0.1366 (0.1989)  loss_refine_obj: 1.0657 (1.4766)  time: 0.9854 (0.9925)  data: 0.0852 (0.0929)  lr: 0.016000  max mem: 10644
2024-05-13 17:02:10,274 maskrcnn_benchmark INFO: eta: 3:58:12  iter: 1600  loss: 1.1988 (1.6091)  loss_rel: 0.1481 (0.1929)  loss_refine_obj: 1.0424 (1.4163)  time: 0.9837 (0.9925)  data: 0.0849 (0.0932)  lr: 0.016000  max mem: 10666
2024-05-13 17:05:27,179 maskrcnn_benchmark INFO: eta: 3:54:41  iter: 1800  loss: 1.1044 (1.5572)  loss_rel: 0.1359 (0.1874)  loss_refine_obj: 0.9707 (1.3698)  time: 0.9997 (0.9916)  data: 0.0868 (0.0926)  lr: 0.016000  max mem: 10666
2024-05-13 17:08:44,328 maskrcnn_benchmark INFO: eta: 3:51:14  iter: 2000  loss: 1.1900 (1.5152)  loss_rel: 0.1276 (0.1830)  loss_refine_obj: 1.0533 (1.3322)  time: 1.0023 (0.9911)  data: 0.0844 (0.0923)  lr: 0.016000  max mem: 10666
2024-05-13 17:12:01,361 maskrcnn_benchmark INFO: eta: 3:47:49  iter: 2200  loss: 1.1008 (1.4795)  loss_rel: 0.1366 (0.1793)  loss_refine_obj: 0.9750 (1.3002)  time: 0.9858 (0.9905)  data: 0.0878 (0.0919)  lr: 0.016000  max mem: 10855
2024-05-13 17:15:18,459 maskrcnn_benchmark INFO: eta: 3:44:25  iter: 2400  loss: 1.1026 (1.4477)  loss_rel: 0.1360 (0.1763)  loss_refine_obj: 0.9733 (1.2714)  time: 0.9881 (0.9901)  data: 0.0859 (0.0915)  lr: 0.016000  max mem: 10855
2024-05-13 17:18:35,206 maskrcnn_benchmark INFO: eta: 3:41:00  iter: 2600  loss: 1.1521 (1.4186)  loss_rel: 0.1497 (0.1736)  loss_refine_obj: 1.0022 (1.2450)  time: 0.9796 (0.9896)  data: 0.0883 (0.0912)  lr: 0.016000  max mem: 10855
2024-05-13 17:21:52,957 maskrcnn_benchmark INFO: eta: 3:37:42  iter: 2800  loss: 1.0732 (1.3940)  loss_rel: 0.1296 (0.1712)  loss_refine_obj: 0.9402 (1.2228)  time: 1.0004 (0.9895)  data: 0.0861 (0.0912)  lr: 0.016000  max mem: 10855
2024-05-13 17:25:11,281 maskrcnn_benchmark INFO: eta: 3:34:25  iter: 3000  loss: 1.0787 (1.3717)  loss_rel: 0.1326 (0.1692)  loss_refine_obj: 0.9517 (1.2024)  time: 0.9932 (0.9897)  data: 0.0861 (0.0914)  lr: 0.016000  max mem: 10855
2024-05-13 17:28:28,849 maskrcnn_benchmark INFO: eta: 3:31:06  iter: 3200  loss: 1.0043 (1.3520)  loss_rel: 0.1471 (0.1674)  loss_refine_obj: 0.8667 (1.1845)  time: 0.9844 (0.9896)  data: 0.0862 (0.0913)  lr: 0.016000  max mem: 10855
2024-05-13 17:31:46,350 maskrcnn_benchmark INFO: eta: 3:27:47  iter: 3400  loss: 1.0225 (1.3336)  loss_rel: 0.1455 (0.1660)  loss_refine_obj: 0.8820 (1.1676)  time: 1.0032 (0.9894)  data: 0.0899 (0.0912)  lr: 0.016000  max mem: 10855
2024-05-13 17:35:06,137 maskrcnn_benchmark INFO: eta: 3:24:35  iter: 3600  loss: 1.0109 (1.3176)  loss_rel: 0.1273 (0.1645)  loss_refine_obj: 0.8833 (1.1531)  time: 1.0097 (0.9900)  data: 0.0919 (0.0916)  lr: 0.016000  max mem: 10855
2024-05-13 17:38:22,389 maskrcnn_benchmark INFO: eta: 3:21:12  iter: 3800  loss: 0.8825 (1.2984)  loss_rel: 0.1272 (0.1630)  loss_refine_obj: 0.7364 (1.1354)  time: 0.9922 (0.9895)  data: 0.0859 (0.0914)  lr: 0.016000  max mem: 10855
2024-05-13 17:41:38,978 maskrcnn_benchmark INFO: ---Total norm 3.09308 clip coef 1.61651-----------------
2024-05-13 17:41:38,987 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 1.72339, (torch.Size([4096, 12544]))
2024-05-13 17:41:38,987 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 1.33262, (torch.Size([4096, 4096]))
2024-05-13 17:41:38,987 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 1.15006, (torch.Size([151, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 0.95032, (torch.Size([512, 4224]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight: 0.45316, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight: 0.44029, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight: 0.43143, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight: 0.43115, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight: 0.42419, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight: 0.41640, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight: 0.40674, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight: 0.37743, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight: 0.36062, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight: 0.36015, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight: 0.33900, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight: 0.33715, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight: 0.27730, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight: 0.27676, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight: 0.27391, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight: 0.26182, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight: 0.18413, (torch.Size([1024, 4608]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight: 0.16821, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight: 0.16724, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight: 0.15929, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 0.15572, (torch.Size([51, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight: 0.15457, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight: 0.15202, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight: 0.15160, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.14836, (torch.Size([4096, 12544]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight: 0.13921, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight: 0.13908, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.09282, (torch.Size([4096, 4096]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight: 0.08770, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight: 0.07594, (torch.Size([512, 4224]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight: 0.07484, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight: 0.07366, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight: 0.06780, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.06285, (torch.Size([151]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight: 0.06195, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight: 0.06157, (torch.Size([512, 2048, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight: 0.05973, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05762, (torch.Size([256, 1024, 3, 3]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05411, (torch.Size([256, 128, 3, 3]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.04937, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 0.04881, (torch.Size([51, 4096]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight: 0.04561, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight: 0.04095, (torch.Size([512, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight: 0.04082, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias: 0.03933, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 0.03829, (torch.Size([4096, 512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias: 0.03811, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight: 0.03727, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias: 0.03652, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias: 0.03465, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias: 0.03445, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight: 0.03400, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias: 0.03384, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight: 0.03377, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight: 0.03372, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight: 0.03327, (torch.Size([512]))
2024-05-13 17:41:38,988 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight: 0.03285, (torch.Size([512, 512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias: 0.03250, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias: 0.03239, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight: 0.03198, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias: 0.03172, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias: 0.03124, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight: 0.03045, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias: 0.03037, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias: 0.03037, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight: 0.03021, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02981, (torch.Size([128, 2, 7, 7]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias: 0.02980, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight: 0.02959, (torch.Size([2048, 512, 1]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias: 0.02954, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias: 0.02911, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias: 0.02899, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias: 0.02753, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias: 0.02716, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias: 0.02500, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias: 0.02421, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.02262, (torch.Size([4096]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias: 0.02205, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias: 0.02122, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias: 0.02059, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias: 0.01846, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight: 0.01640, (torch.Size([512, 512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight: 0.01577, (torch.Size([512, 512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias: 0.01316, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias: 0.01262, (torch.Size([2048]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias: 0.01260, (torch.Size([2048]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias: 0.01222, (torch.Size([2048]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias: 0.01220, (torch.Size([2048]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias: 0.01201, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias: 0.01086, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.00978, (torch.Size([4096]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.00813, (torch.Size([51]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.00813, (torch.Size([51]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias: 0.00797, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias: 0.00729, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias: 0.00701, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00673, (torch.Size([128]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias: 0.00666, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias: 0.00654, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias: 0.00653, (torch.Size([1024]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight: 0.00591, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias: 0.00572, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias: 0.00536, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias: 0.00480, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight: 0.00436, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias: 0.00429, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias: 0.00427, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight: 0.00425, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight: 0.00394, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00385, (torch.Size([128, 32]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias: 0.00371, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight: 0.00331, (torch.Size([128, 64]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00324, (torch.Size([128]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias: 0.00313, (torch.Size([512]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00260, (torch.Size([32, 9]))
2024-05-13 17:41:38,989 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight: 0.00259, (torch.Size([64, 21]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias: 0.00204, (torch.Size([2048]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.00191, (torch.Size([4096]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00163, (torch.Size([128]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00158, (torch.Size([32]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias: 0.00155, (torch.Size([2048]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00140, (torch.Size([4096]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00129, (torch.Size([256]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00106, (torch.Size([256]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias: 0.00075, (torch.Size([128]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00071, (torch.Size([256]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias: 0.00069, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00062, (torch.Size([4096]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00062, (torch.Size([256]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00050, (torch.Size([128]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight: 0.00042, (torch.Size([512, 512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight: 0.00040, (torch.Size([512, 512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias: 0.00035, (torch.Size([64]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias: 0.00012, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 17:41:38,990 maskrcnn_benchmark INFO: -------------------------------
2024-05-13 17:41:38,992 maskrcnn_benchmark INFO: eta: 3:17:50  iter: 4000  loss: 0.9310 (1.2803)  loss_rel: 0.1341 (0.1617)  loss_refine_obj: 0.8077 (1.1186)  time: 1.0026 (0.9892)  data: 0.0859 (0.0913)  lr: 0.016000  max mem: 10855
2024-05-13 17:44:59,662 maskrcnn_benchmark INFO: eta: 3:14:40  iter: 4200  loss: 0.8692 (1.2643)  loss_rel: 0.1359 (0.1605)  loss_refine_obj: 0.7393 (1.1038)  time: 0.9752 (0.9899)  data: 0.0850 (0.0919)  lr: 0.016000  max mem: 10855
2024-05-13 17:48:16,446 maskrcnn_benchmark INFO: eta: 3:11:19  iter: 4400  loss: 0.9417 (1.2504)  loss_rel: 0.1273 (0.1593)  loss_refine_obj: 0.7915 (1.0911)  time: 0.9943 (0.9896)  data: 0.0857 (0.0917)  lr: 0.016000  max mem: 10855
2024-05-13 17:51:33,649 maskrcnn_benchmark INFO: eta: 3:07:59  iter: 4600  loss: 0.8874 (1.2371)  loss_rel: 0.1295 (0.1582)  loss_refine_obj: 0.7603 (1.0788)  time: 0.9799 (0.9894)  data: 0.0862 (0.0915)  lr: 0.016000  max mem: 10855
2024-05-13 17:54:53,683 maskrcnn_benchmark INFO: eta: 3:04:46  iter: 4800  loss: 0.9583 (1.2253)  loss_rel: 0.1256 (0.1571)  loss_refine_obj: 0.8386 (1.0682)  time: 1.0155 (0.9899)  data: 0.0849 (0.0917)  lr: 0.016000  max mem: 10855
2024-05-13 17:58:10,822 maskrcnn_benchmark INFO: eta: 3:01:26  iter: 5000  loss: 0.9721 (1.2134)  loss_rel: 0.1434 (0.1563)  loss_refine_obj: 0.8203 (1.0571)  time: 0.9930 (0.9897)  data: 0.0866 (0.0915)  lr: 0.016000  max mem: 10855
2024-05-13 18:01:27,997 maskrcnn_benchmark INFO: eta: 2:58:07  iter: 5200  loss: 0.9492 (1.2024)  loss_rel: 0.1345 (0.1554)  loss_refine_obj: 0.8089 (1.0470)  time: 0.9934 (0.9896)  data: 0.0865 (0.0914)  lr: 0.016000  max mem: 10855
2024-05-13 18:04:45,647 maskrcnn_benchmark INFO: eta: 2:54:48  iter: 5400  loss: 0.8898 (1.1928)  loss_rel: 0.1334 (0.1545)  loss_refine_obj: 0.7426 (1.0383)  time: 0.9926 (0.9895)  data: 0.0865 (0.0913)  lr: 0.016000  max mem: 10855
2024-05-13 18:08:03,093 maskrcnn_benchmark INFO: eta: 2:51:30  iter: 5600  loss: 0.8893 (1.1835)  loss_rel: 0.1372 (0.1539)  loss_refine_obj: 0.7568 (1.0296)  time: 0.9769 (0.9894)  data: 0.0846 (0.0912)  lr: 0.016000  max mem: 10855
2024-05-13 18:11:20,066 maskrcnn_benchmark INFO: eta: 2:48:10  iter: 5800  loss: 0.8955 (1.1749)  loss_rel: 0.1400 (0.1532)  loss_refine_obj: 0.7704 (1.0217)  time: 0.9812 (0.9893)  data: 0.0856 (0.0911)  lr: 0.016000  max mem: 10855
2024-05-13 18:14:40,578 maskrcnn_benchmark INFO: eta: 2:44:57  iter: 6000  loss: 0.9419 (1.1667)  loss_rel: 0.1265 (0.1524)  loss_refine_obj: 0.8321 (1.0143)  time: 0.9895 (0.9897)  data: 0.0856 (0.0914)  lr: 0.016000  max mem: 10855
2024-05-13 18:17:59,033 maskrcnn_benchmark INFO: eta: 2:41:40  iter: 6200  loss: 0.9494 (1.1599)  loss_rel: 0.1228 (0.1518)  loss_refine_obj: 0.8387 (1.0081)  time: 0.9805 (0.9898)  data: 0.0843 (0.0915)  lr: 0.016000  max mem: 10855
2024-05-13 18:21:17,430 maskrcnn_benchmark INFO: eta: 2:38:22  iter: 6400  loss: 0.9113 (1.1530)  loss_rel: 0.1333 (0.1512)  loss_refine_obj: 0.7773 (1.0018)  time: 0.9879 (0.9899)  data: 0.0881 (0.0916)  lr: 0.016000  max mem: 10855
2024-05-13 18:24:35,527 maskrcnn_benchmark INFO: eta: 2:35:05  iter: 6600  loss: 0.9174 (1.1463)  loss_rel: 0.1310 (0.1507)  loss_refine_obj: 0.7642 (0.9956)  time: 0.9879 (0.9899)  data: 0.0846 (0.0915)  lr: 0.016000  max mem: 10855
2024-05-13 18:27:53,167 maskrcnn_benchmark INFO: eta: 2:31:46  iter: 6800  loss: 0.9018 (1.1401)  loss_rel: 0.1220 (0.1502)  loss_refine_obj: 0.7665 (0.9899)  time: 0.9819 (0.9898)  data: 0.0836 (0.0914)  lr: 0.016000  max mem: 10855
2024-05-13 18:31:10,508 maskrcnn_benchmark INFO: eta: 2:28:27  iter: 7000  loss: 0.9375 (1.1345)  loss_rel: 0.1228 (0.1496)  loss_refine_obj: 0.8064 (0.9849)  time: 0.9718 (0.9898)  data: 0.0842 (0.0914)  lr: 0.016000  max mem: 10905
2024-05-13 18:34:28,445 maskrcnn_benchmark INFO: eta: 2:25:09  iter: 7200  loss: 0.8839 (1.1287)  loss_rel: 0.1312 (0.1492)  loss_refine_obj: 0.7700 (0.9795)  time: 0.9875 (0.9898)  data: 0.0835 (0.0915)  lr: 0.016000  max mem: 10905
2024-05-13 18:37:47,614 maskrcnn_benchmark INFO: eta: 2:21:53  iter: 7400  loss: 0.7631 (1.1203)  loss_rel: 0.1289 (0.1486)  loss_refine_obj: 0.6444 (0.9717)  time: 0.9662 (0.9899)  data: 0.0883 (0.0917)  lr: 0.016000  max mem: 10905
2024-05-13 18:41:05,542 maskrcnn_benchmark INFO: eta: 2:18:35  iter: 7600  loss: 0.8443 (1.1125)  loss_rel: 0.1234 (0.1481)  loss_refine_obj: 0.7074 (0.9644)  time: 0.9853 (0.9899)  data: 0.0873 (0.0918)  lr: 0.016000  max mem: 10905
2024-05-13 18:44:21,997 maskrcnn_benchmark INFO: eta: 2:15:15  iter: 7800  loss: 0.7517 (1.1048)  loss_rel: 0.1324 (0.1475)  loss_refine_obj: 0.6328 (0.9572)  time: 0.9898 (0.9897)  data: 0.0870 (0.0917)  lr: 0.016000  max mem: 10905
2024-05-13 18:47:39,678 maskrcnn_benchmark INFO: ---Total norm 2.56840 clip coef 1.94674-----------------
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 1.61049, (torch.Size([4096, 12544]))
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 1.29649, (torch.Size([4096, 4096]))
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 0.75887, (torch.Size([151, 512]))
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 0.72973, (torch.Size([512, 4224]))
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight: 0.30174, (torch.Size([512, 512]))
2024-05-13 18:47:39,686 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight: 0.28737, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight: 0.28714, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight: 0.28115, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight: 0.28096, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight: 0.27017, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight: 0.26283, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight: 0.25402, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight: 0.24857, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight: 0.24437, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight: 0.23696, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight: 0.23652, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight: 0.20573, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight: 0.20299, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight: 0.19995, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight: 0.19250, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight: 0.14425, (torch.Size([1024, 4608]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.11884, (torch.Size([4096, 12544]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight: 0.11266, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight: 0.10687, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 0.10627, (torch.Size([51, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight: 0.10464, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight: 0.10420, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight: 0.10121, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight: 0.09832, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight: 0.08051, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight: 0.08041, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight: 0.07677, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07623, (torch.Size([4096, 4096]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight: 0.06716, (torch.Size([512, 4224]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight: 0.06008, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight: 0.05930, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.05405, (torch.Size([256, 1024, 3, 3]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight: 0.05262, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight: 0.04905, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.04772, (torch.Size([151]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight: 0.04513, (torch.Size([512, 2048, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.04425, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight: 0.04394, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04162, (torch.Size([256, 128, 3, 3]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias: 0.03775, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight: 0.03619, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias: 0.03454, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight: 0.03295, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 0.03170, (torch.Size([51, 4096]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight: 0.03144, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight: 0.03131, (torch.Size([512, 512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias: 0.03075, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias: 0.03017, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight: 0.02996, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight: 0.02989, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias: 0.02981, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias: 0.02972, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight: 0.02959, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias: 0.02891, (torch.Size([512]))
2024-05-13 18:47:39,687 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight: 0.02849, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias: 0.02846, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight: 0.02811, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight: 0.02807, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias: 0.02709, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight: 0.02699, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 0.02694, (torch.Size([4096, 512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias: 0.02685, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias: 0.02659, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias: 0.02642, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias: 0.02642, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias: 0.02627, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias: 0.02578, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias: 0.02562, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight: 0.02550, (torch.Size([512, 512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias: 0.02477, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias: 0.02430, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight: 0.02376, (torch.Size([2048, 512, 1]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias: 0.02326, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02248, (torch.Size([128, 2, 7, 7]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias: 0.02087, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias: 0.02018, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias: 0.01928, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias: 0.01845, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.01839, (torch.Size([4096]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias: 0.01694, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight: 0.01407, (torch.Size([512, 512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight: 0.01273, (torch.Size([512, 512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias: 0.01098, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias: 0.01063, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias: 0.01055, (torch.Size([2048]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias: 0.01036, (torch.Size([2048]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias: 0.01030, (torch.Size([2048]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias: 0.00972, (torch.Size([2048]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.00916, (torch.Size([4096]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias: 0.00587, (torch.Size([1024]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias: 0.00580, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.00546, (torch.Size([51]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.00546, (torch.Size([51]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias: 0.00510, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias: 0.00504, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias: 0.00482, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias: 0.00476, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00475, (torch.Size([128]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias: 0.00465, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight: 0.00452, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00444, (torch.Size([128]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00417, (torch.Size([128, 32]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias: 0.00397, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight: 0.00393, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight: 0.00376, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias: 0.00374, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias: 0.00357, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight: 0.00348, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight: 0.00332, (torch.Size([128, 64]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias: 0.00322, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias: 0.00320, (torch.Size([512]))
2024-05-13 18:47:39,688 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias: 0.00296, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias: 0.00249, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight: 0.00226, (torch.Size([64, 21]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00201, (torch.Size([32, 9]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00153, (torch.Size([32]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.00151, (torch.Size([4096]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias: 0.00148, (torch.Size([2048]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00148, (torch.Size([256]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00146, (torch.Size([4096]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00133, (torch.Size([128]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias: 0.00119, (torch.Size([2048]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00081, (torch.Size([256]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00066, (torch.Size([256]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias: 0.00065, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00062, (torch.Size([256]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00061, (torch.Size([4096]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias: 0.00049, (torch.Size([128]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00039, (torch.Size([128]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias: 0.00023, (torch.Size([64]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight: 0.00012, (torch.Size([512, 512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight: 0.00012, (torch.Size([512, 512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias: 0.00005, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 18:47:39,689 maskrcnn_benchmark INFO: -------------------------------
2024-05-13 18:47:39,691 maskrcnn_benchmark INFO: eta: 2:11:57  iter: 8000  loss: 0.7934 (1.0980)  loss_rel: 0.1290 (0.1471)  loss_refine_obj: 0.6673 (0.9510)  time: 0.9896 (0.9897)  data: 0.0874 (0.0917)  lr: 0.016000  max mem: 10905
2024-05-13 18:50:56,475 maskrcnn_benchmark INFO: eta: 2:08:38  iter: 8200  loss: 0.8143 (1.0918)  loss_rel: 0.1186 (0.1466)  loss_refine_obj: 0.6778 (0.9452)  time: 0.9662 (0.9895)  data: 0.0844 (0.0916)  lr: 0.016000  max mem: 10905
2024-05-13 18:54:13,832 maskrcnn_benchmark INFO: eta: 2:05:20  iter: 8400  loss: 0.7904 (1.0857)  loss_rel: 0.1233 (0.1462)  loss_refine_obj: 0.6736 (0.9394)  time: 0.9674 (0.9895)  data: 0.0858 (0.0916)  lr: 0.016000  max mem: 10905
2024-05-13 18:57:31,000 maskrcnn_benchmark INFO: eta: 2:02:01  iter: 8600  loss: 0.8373 (1.0802)  loss_rel: 0.1146 (0.1458)  loss_refine_obj: 0.6874 (0.9344)  time: 0.9796 (0.9894)  data: 0.0869 (0.0915)  lr: 0.016000  max mem: 10905
2024-05-13 19:00:48,473 maskrcnn_benchmark INFO: eta: 1:58:43  iter: 8800  loss: 0.8520 (1.0746)  loss_rel: 0.1255 (0.1454)  loss_refine_obj: 0.7117 (0.9292)  time: 0.9824 (0.9893)  data: 0.0890 (0.0914)  lr: 0.016000  max mem: 10905
2024-05-13 19:04:05,564 maskrcnn_benchmark INFO: eta: 1:55:24  iter: 9000  loss: 0.8118 (1.0695)  loss_rel: 0.1206 (0.1451)  loss_refine_obj: 0.6850 (0.9244)  time: 0.9916 (0.9893)  data: 0.0858 (0.0914)  lr: 0.016000  max mem: 10905
2024-05-13 19:07:24,342 maskrcnn_benchmark INFO: eta: 1:52:07  iter: 9200  loss: 0.8138 (1.0645)  loss_rel: 0.1339 (0.1448)  loss_refine_obj: 0.6927 (0.9197)  time: 0.9613 (0.9894)  data: 0.0852 (0.0915)  lr: 0.016000  max mem: 10905
2024-05-13 19:10:43,321 maskrcnn_benchmark INFO: eta: 1:48:50  iter: 9400  loss: 0.8052 (1.0597)  loss_rel: 0.1248 (0.1444)  loss_refine_obj: 0.6675 (0.9153)  time: 0.9849 (0.9895)  data: 0.0874 (0.0916)  lr: 0.016000  max mem: 10905
2024-05-13 19:14:00,926 maskrcnn_benchmark INFO: eta: 1:45:32  iter: 9600  loss: 0.8240 (1.0549)  loss_rel: 0.1151 (0.1441)  loss_refine_obj: 0.7119 (0.9109)  time: 1.0050 (0.9894)  data: 0.0879 (0.0915)  lr: 0.016000  max mem: 10905
2024-05-13 19:17:19,885 maskrcnn_benchmark INFO: eta: 1:42:15  iter: 9800  loss: 0.8300 (1.0502)  loss_rel: 0.1318 (0.1438)  loss_refine_obj: 0.6916 (0.9064)  time: 0.9938 (0.9896)  data: 0.0867 (0.0916)  lr: 0.016000  max mem: 10905
2024-05-13 19:20:53,975 maskrcnn_benchmark INFO: eta: 1:39:07  iter: 10000  loss: 0.8731 (1.0461)  loss_rel: 0.1162 (0.1434)  loss_refine_obj: 0.7621 (0.9027)  time: 1.1020 (0.9912)  data: 0.1793 (0.0931)  lr: 0.016000  max mem: 10905
2024-05-13 19:20:53,976 maskrcnn_benchmark INFO: Start validating
2024-05-13 19:20:54,086 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2024-05-13 19:25:02,671 maskrcnn_benchmark INFO: Total run time: 0:04:08.585237 (0.049717047357559205 s / img per device, on 1 devices)
2024-05-13 19:25:02,671 maskrcnn_benchmark INFO: Model inference time: 0:03:36.444282 (0.04328885631561279 s / img per device, on 1 devices)
2024-05-13 19:28:00,610 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5933
====================================================================================================
SGG eval:     R @ 20: 0.4040;     R @ 50: 0.4330;     R @ 100: 0.4424;  for mode=sgcls, type=Recall(Main).
SGG eval:  ng-R @ 20: 0.4589;  ng-R @ 50: 0.5285;  ng-R @ 100: 0.5613;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:    zR @ 20: 0.0524;    zR @ 50: 0.0588;    zR @ 100: 0.0780;  for mode=sgcls, type=Zero Shot Recall.
SGG eval: ng-zR @ 20: 0.0652; ng-zR @ 50: 0.0972; ng-zR @ 100: 0.1870;  for mode=sgcls, type=No Graph Constraint Zero Shot Recall.
SGG eval:    mR @ 20: 0.0854;    mR @ 50: 0.1069;    mR @ 100: 0.1164;  for mode=sgcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1649) (across:0.0000) (against:0.0000) (along:0.1154) (and:0.0000) (at:0.1074) (attached to:0.0183) (behind:0.3217) (belonging to:0.0000) (between:0.0000) (carrying:0.2939) (covered in:0.0000) (covering:0.0381) (eating:0.4048) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.5166) (holding:0.3085) (in:0.2584) (in front of:0.2393) (laying on:0.0476) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2881) (of:0.2744) (on:0.5906) (on back of:0.0000) (over:0.0427) (painted on:0.0000) (parked on:0.1513) (part of:0.0000) (playing:0.0000) (riding:0.1414) (says:0.0000) (sitting on:0.1618) (standing on:0.0391) (to:0.0000) (under:0.1896) (using:0.0000) (walking in:0.0000) (walking on:0.2184) (watching:0.1667) (wearing:0.5206) (wears:0.0177) (with:0.1607) 
--------------------------------------------------------
SGG eval:    mR @ 20: 0.0903;    mR @ 50: 0.1120;    mR @ 100: 0.1201;  for mode=sgcls, type=Mean Micro Recall.
----------------------- Details ------------------------
(above:0.1021) (across:0.0000) (against:0.0000) (along:0.1143) (and:0.0000) (at:0.2035) (attached to:0.0075) (behind:0.3159) (belonging to:0.0000) (between:0.0000) (carrying:0.2857) (covered in:0.0000) (covering:0.0274) (eating:0.2609) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0244) (has:0.5884) (holding:0.3307) (in:0.2737) (in front of:0.2514) (laying on:0.0400) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2906) (of:0.2691) (on:0.6374) (on back of:0.0000) (over:0.0388) (painted on:0.0000) (parked on:0.1878) (part of:0.0000) (playing:0.0000) (riding:0.1414) (says:0.0000) (sitting on:0.1466) (standing on:0.0368) (to:0.0000) (under:0.2000) (using:0.0000) (walking in:0.0000) (walking on:0.1930) (watching:0.3214) (wearing:0.5441) (wears:0.0144) (with:0.1579) 
--------------------------------------------------------
SGG eval: ng-mR @ 20: 0.1382; ng-mR @ 50: 0.2144; ng-mR @ 100: 0.2783;  for mode=sgcls, type=No Graph Constraint Mean Recall.
----------------------- Details ------------------------
(above:0.4772) (across:0.0556) (against:0.0000) (along:0.4551) (and:0.0806) (at:0.4298) (attached to:0.3650) (behind:0.3981) (belonging to:0.2143) (between:0.0385) (carrying:0.4167) (covered in:0.1786) (covering:0.1891) (eating:0.2619) (flying in:0.0000) (for:0.3056) (from:0.0000) (growing on:0.0667) (hanging from:0.6287) (has:0.5821) (holding:0.4003) (in:0.5067) (in front of:0.4359) (laying on:0.1905) (looking at:0.2174) (lying on:0.2222) (made of:0.0000) (mounted on:0.0435) (near:0.4543) (of:0.5593) (on:0.6169) (on back of:0.0909) (over:0.2043) (painted on:0.1429) (parked on:0.7160) (part of:0.1771) (playing:0.0000) (riding:0.4152) (says:0.0000) (sitting on:0.3822) (standing on:0.2587) (to:0.2222) (under:0.3384) (using:0.1538) (walking in:0.0769) (walking on:0.2907) (watching:0.2353) (wearing:0.5224) (wears:0.4593) (with:0.4367) 
--------------------------------------------------------
SGG eval: zs-mR @ 20: 0.0107; zs-mR @ 50: 0.0129; zs-mR @ 100: 0.0191;  for mode=sgcls, type=Zero-Shot Mean Recall.
----------------------- Details ------------------------
(above:0.0000) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.2222) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.1000) (holding:0.0000) (in:0.0833) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0714) (of:0.0000) (on:0.2083) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.2000) (standing on:0.0000) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0714) 
--------------------------------------------------------
SGG eval:     A @ 20: 0.3531;     A @ 50: 0.3539;     A @ 100: 0.3539;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2024-05-13 19:28:00,826 maskrcnn_benchmark INFO: Validation Result: 0.4424
2024-05-13 19:31:19,521 maskrcnn_benchmark INFO: eta: 1:39:51  iter: 10200  loss: 0.7537 (1.0418)  loss_rel: 0.1202 (0.1431)  loss_refine_obj: 0.6379 (0.8987)  time: 0.9847 (1.0331)  data: 0.0906 (0.1350)  lr: 0.001600  max mem: 10905
2024-05-13 19:34:37,499 maskrcnn_benchmark INFO: eta: 1:36:20  iter: 10400  loss: 0.7510 (1.0371)  loss_rel: 0.1254 (0.1428)  loss_refine_obj: 0.6195 (0.8943)  time: 0.9833 (1.0322)  data: 0.0906 (0.1342)  lr: 0.001600  max mem: 10905
2024-05-13 19:37:55,639 maskrcnn_benchmark INFO: eta: 1:32:49  iter: 10600  loss: 0.7339 (1.0324)  loss_rel: 0.1279 (0.1425)  loss_refine_obj: 0.6176 (0.8899)  time: 0.9905 (1.0315)  data: 0.0896 (0.1334)  lr: 0.001600  max mem: 10905
2024-05-13 19:41:15,433 maskrcnn_benchmark INFO: eta: 1:29:20  iter: 10800  loss: 0.8212 (1.0280)  loss_rel: 0.1230 (0.1421)  loss_refine_obj: 0.6963 (0.8859)  time: 0.9883 (1.0309)  data: 0.0886 (0.1327)  lr: 0.001600  max mem: 10905
2024-05-13 19:44:38,447 maskrcnn_benchmark INFO: eta: 1:25:52  iter: 11000  loss: 0.6463 (1.0217)  loss_rel: 0.1163 (0.1417)  loss_refine_obj: 0.5219 (0.8800)  time: 0.9906 (1.0306)  data: 0.0909 (0.1324)  lr: 0.001600  max mem: 10905
2024-05-13 19:48:00,549 maskrcnn_benchmark INFO: eta: 1:22:24  iter: 11200  loss: 0.6845 (1.0156)  loss_rel: 0.1196 (0.1413)  loss_refine_obj: 0.5604 (0.8742)  time: 1.0036 (1.0302)  data: 0.0905 (0.1320)  lr: 0.001600  max mem: 10905
2024-05-13 19:51:18,976 maskrcnn_benchmark INFO: eta: 1:18:55  iter: 11400  loss: 0.6812 (1.0096)  loss_rel: 0.1201 (0.1410)  loss_refine_obj: 0.5751 (0.8686)  time: 0.9790 (1.0295)  data: 0.0879 (0.1314)  lr: 0.001600  max mem: 10905
2024-05-13 19:54:37,319 maskrcnn_benchmark INFO: eta: 1:15:27  iter: 11600  loss: 0.7042 (1.0038)  loss_rel: 0.1089 (0.1407)  loss_refine_obj: 0.5739 (0.8631)  time: 0.9989 (1.0289)  data: 0.0907 (0.1307)  lr: 0.001600  max mem: 10905
2024-05-13 19:57:55,544 maskrcnn_benchmark INFO: eta: 1:11:58  iter: 11800  loss: 0.6589 (0.9982)  loss_rel: 0.1163 (0.1403)  loss_refine_obj: 0.5426 (0.8579)  time: 0.9831 (1.0282)  data: 0.0892 (0.1301)  lr: 0.001600  max mem: 10905
2024-05-13 20:01:14,871 maskrcnn_benchmark INFO: ---Total norm 2.43150 clip coef 2.05634-----------------
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 1.63773, (torch.Size([4096, 12544]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 1.23389, (torch.Size([4096, 4096]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 0.63839, (torch.Size([512, 4224]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 0.62757, (torch.Size([151, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight: 0.26203, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight: 0.24965, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight: 0.23923, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight: 0.23317, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight: 0.23265, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight: 0.23010, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight: 0.22531, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight: 0.21726, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight: 0.21453, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight: 0.21016, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight: 0.20282, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight: 0.20219, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight: 0.17737, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight: 0.17712, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight: 0.17574, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight: 0.17121, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight: 0.13671, (torch.Size([1024, 4608]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.11876, (torch.Size([4096, 12544]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 0.09537, (torch.Size([51, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight: 0.09436, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight: 0.09087, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight: 0.08430, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight: 0.08225, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight: 0.08162, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight: 0.08062, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight: 0.07779, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight: 0.07736, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight: 0.07332, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.07173, (torch.Size([4096, 4096]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight: 0.06448, (torch.Size([512, 4224]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight: 0.06112, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight: 0.05820, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight: 0.04883, (torch.Size([512, 512]))
2024-05-13 20:01:14,880 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.04759, (torch.Size([256, 1024, 3, 3]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight: 0.04496, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight: 0.04346, (torch.Size([512, 2048, 1]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias: 0.04244, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04215, (torch.Size([256, 128, 3, 3]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.04028, (torch.Size([151]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight: 0.03902, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight: 0.03745, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.03614, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias: 0.03482, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias: 0.03378, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight: 0.03196, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight: 0.03127, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias: 0.03045, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias: 0.02925, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias: 0.02716, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias: 0.02667, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias: 0.02660, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight: 0.02578, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight: 0.02567, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias: 0.02551, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 0.02539, (torch.Size([51, 4096]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02538, (torch.Size([128, 2, 7, 7]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight: 0.02493, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias: 0.02491, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias: 0.02452, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias: 0.02437, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight: 0.02407, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight: 0.02406, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias: 0.02395, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias: 0.02386, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias: 0.02377, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight: 0.02371, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias: 0.02369, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias: 0.02334, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight: 0.02326, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight: 0.02257, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias: 0.02250, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias: 0.02224, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight: 0.02202, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias: 0.02184, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight: 0.02139, (torch.Size([2048, 512, 1]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 0.02084, (torch.Size([4096, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias: 0.01900, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.01830, (torch.Size([4096]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias: 0.01690, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias: 0.01609, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias: 0.01560, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight: 0.01259, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight: 0.01254, (torch.Size([512, 512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias: 0.01161, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias: 0.01084, (torch.Size([512]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias: 0.00948, (torch.Size([2048]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias: 0.00943, (torch.Size([2048]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias: 0.00904, (torch.Size([2048]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias: 0.00893, (torch.Size([2048]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.00888, (torch.Size([4096]))
2024-05-13 20:01:14,881 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias: 0.00677, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.00631, (torch.Size([51]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.00631, (torch.Size([51]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias: 0.00563, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias: 0.00539, (torch.Size([1024]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias: 0.00510, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias: 0.00481, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight: 0.00481, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias: 0.00477, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias: 0.00459, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00452, (torch.Size([128]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias: 0.00437, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight: 0.00419, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias: 0.00411, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias: 0.00410, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias: 0.00391, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight: 0.00389, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias: 0.00366, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias: 0.00362, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight: 0.00351, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight: 0.00345, (torch.Size([128, 64]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias: 0.00314, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight: 0.00259, (torch.Size([64, 21]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00255, (torch.Size([128]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00247, (torch.Size([128, 32]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00185, (torch.Size([32, 9]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias: 0.00161, (torch.Size([2048]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias: 0.00139, (torch.Size([2048]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00134, (torch.Size([128]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00128, (torch.Size([4096]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00128, (torch.Size([32]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.00122, (torch.Size([4096]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias: 0.00092, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00085, (torch.Size([256]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00083, (torch.Size([256]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias: 0.00068, (torch.Size([128]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00063, (torch.Size([256]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00056, (torch.Size([4096]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00047, (torch.Size([256]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias: 0.00035, (torch.Size([64]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00030, (torch.Size([128]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight: 0.00008, (torch.Size([512, 512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight: 0.00008, (torch.Size([512, 512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias: 0.00005, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 20:01:14,882 maskrcnn_benchmark INFO: -------------------------------
2024-05-13 20:01:14,884 maskrcnn_benchmark INFO: eta: 1:08:30  iter: 12000  loss: 0.6227 (0.9926)  loss_rel: 0.1198 (0.1400)  loss_refine_obj: 0.5119 (0.8526)  time: 0.9757 (1.0277)  data: 0.0867 (0.1296)  lr: 0.001600  max mem: 10905
2024-05-13 20:04:37,511 maskrcnn_benchmark INFO: eta: 1:05:04  iter: 12200  loss: 0.6224 (0.9872)  loss_rel: 0.1086 (0.1396)  loss_refine_obj: 0.5019 (0.8476)  time: 1.0015 (1.0275)  data: 0.0917 (0.1293)  lr: 0.001600  max mem: 10905
2024-05-13 20:07:55,269 maskrcnn_benchmark INFO: eta: 1:01:36  iter: 12400  loss: 0.6741 (0.9819)  loss_rel: 0.1199 (0.1393)  loss_refine_obj: 0.5594 (0.8425)  time: 0.9626 (1.0269)  data: 0.0908 (0.1287)  lr: 0.001600  max mem: 10905
2024-05-13 20:11:19,075 maskrcnn_benchmark INFO: eta: 0:58:10  iter: 12600  loss: 0.6504 (0.9769)  loss_rel: 0.1171 (0.1390)  loss_refine_obj: 0.5403 (0.8379)  time: 1.0064 (1.0267)  data: 0.0927 (0.1284)  lr: 0.001600  max mem: 10905
2024-05-13 20:14:38,642 maskrcnn_benchmark INFO: eta: 0:54:44  iter: 12800  loss: 0.6822 (0.9721)  loss_rel: 0.1233 (0.1388)  loss_refine_obj: 0.5539 (0.8333)  time: 0.9953 (1.0263)  data: 0.0881 (0.1280)  lr: 0.001600  max mem: 10905
2024-05-13 20:17:56,642 maskrcnn_benchmark INFO: eta: 0:51:17  iter: 13000  loss: 0.6341 (0.9671)  loss_rel: 0.1149 (0.1385)  loss_refine_obj: 0.4916 (0.8286)  time: 0.9996 (1.0257)  data: 0.0916 (0.1274)  lr: 0.001600  max mem: 10905
2024-05-13 20:21:17,305 maskrcnn_benchmark INFO: eta: 0:47:51  iter: 13200  loss: 0.6306 (0.9626)  loss_rel: 0.1082 (0.1382)  loss_refine_obj: 0.5030 (0.8243)  time: 0.9841 (1.0254)  data: 0.0920 (0.1271)  lr: 0.001600  max mem: 10905
2024-05-13 20:24:34,950 maskrcnn_benchmark INFO: eta: 0:44:24  iter: 13400  loss: 0.6457 (0.9580)  loss_rel: 0.1108 (0.1379)  loss_refine_obj: 0.5278 (0.8200)  time: 0.9978 (1.0248)  data: 0.0913 (0.1265)  lr: 0.001600  max mem: 10905
2024-05-13 20:27:53,353 maskrcnn_benchmark INFO: eta: 0:40:58  iter: 13600  loss: 0.6816 (0.9535)  loss_rel: 0.1193 (0.1377)  loss_refine_obj: 0.5579 (0.8158)  time: 0.9890 (1.0243)  data: 0.0893 (0.1260)  lr: 0.001600  max mem: 10905
2024-05-13 20:31:13,693 maskrcnn_benchmark INFO: eta: 0:37:32  iter: 13800  loss: 0.6881 (0.9493)  loss_rel: 0.1218 (0.1374)  loss_refine_obj: 0.5576 (0.8118)  time: 0.9898 (1.0240)  data: 0.0882 (0.1256)  lr: 0.001600  max mem: 11247
2024-05-13 20:34:37,785 maskrcnn_benchmark INFO: eta: 0:34:07  iter: 14000  loss: 0.7539 (0.9452)  loss_rel: 0.1230 (0.1372)  loss_refine_obj: 0.5973 (0.8080)  time: 0.9908 (1.0240)  data: 0.0906 (0.1255)  lr: 0.001600  max mem: 11247
2024-05-13 20:37:58,824 maskrcnn_benchmark INFO: eta: 0:30:42  iter: 14200  loss: 0.6163 (0.9411)  loss_rel: 0.1192 (0.1369)  loss_refine_obj: 0.4893 (0.8042)  time: 0.9928 (1.0237)  data: 0.0904 (0.1252)  lr: 0.001600  max mem: 11247
2024-05-13 20:41:16,554 maskrcnn_benchmark INFO: eta: 0:27:17  iter: 14400  loss: 0.6070 (0.9370)  loss_rel: 0.1138 (0.1367)  loss_refine_obj: 0.5027 (0.8004)  time: 0.9935 (1.0232)  data: 0.0870 (0.1247)  lr: 0.001600  max mem: 11247
2024-05-13 20:44:34,285 maskrcnn_benchmark INFO: eta: 0:23:51  iter: 14600  loss: 0.6100 (0.9326)  loss_rel: 0.1139 (0.1365)  loss_refine_obj: 0.5002 (0.7961)  time: 0.9796 (1.0227)  data: 0.0906 (0.1243)  lr: 0.001600  max mem: 11247
2024-05-13 20:47:52,539 maskrcnn_benchmark INFO: eta: 0:20:26  iter: 14800  loss: 0.6015 (0.9283)  loss_rel: 0.1190 (0.1362)  loss_refine_obj: 0.4620 (0.7921)  time: 0.9917 (1.0223)  data: 0.0899 (0.1238)  lr: 0.001600  max mem: 11247
2024-05-13 20:51:11,733 maskrcnn_benchmark INFO: eta: 0:17:01  iter: 15000  loss: 0.6253 (0.9243)  loss_rel: 0.1135 (0.1359)  loss_refine_obj: 0.5129 (0.7884)  time: 0.9938 (1.0220)  data: 0.0881 (0.1235)  lr: 0.001600  max mem: 11247
2024-05-13 20:54:30,036 maskrcnn_benchmark INFO: eta: 0:13:37  iter: 15200  loss: 0.6488 (0.9203)  loss_rel: 0.1139 (0.1357)  loss_refine_obj: 0.5341 (0.7846)  time: 0.9802 (1.0216)  data: 0.0869 (0.1231)  lr: 0.001600  max mem: 11247
2024-05-13 20:57:52,434 maskrcnn_benchmark INFO: eta: 0:10:12  iter: 15400  loss: 0.6057 (0.9165)  loss_rel: 0.1183 (0.1355)  loss_refine_obj: 0.4937 (0.7810)  time: 1.0170 (1.0214)  data: 0.0918 (0.1229)  lr: 0.001600  max mem: 11247
2024-05-13 21:01:10,945 maskrcnn_benchmark INFO: eta: 0:06:48  iter: 15600  loss: 0.6018 (0.9127)  loss_rel: 0.1146 (0.1353)  loss_refine_obj: 0.4763 (0.7774)  time: 0.9895 (1.0211)  data: 0.0869 (0.1225)  lr: 0.001600  max mem: 11247
2024-05-13 21:04:28,451 maskrcnn_benchmark INFO: eta: 0:03:24  iter: 15800  loss: 0.5427 (0.9090)  loss_rel: 0.1205 (0.1351)  loss_refine_obj: 0.4260 (0.7740)  time: 0.9985 (1.0206)  data: 0.0901 (0.1221)  lr: 0.001600  max mem: 11247
2024-05-13 21:08:00,748 maskrcnn_benchmark INFO: ---Total norm 2.52434 clip coef 1.98071-----------------
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.weight: 1.74752, (torch.Size([4096, 12544]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.weight: 1.29635, (torch.Size([4096, 4096]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.weight: 0.64848, (torch.Size([512, 4224]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.weight: 0.56179, (torch.Size([151, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.weight: 0.23912, (torch.Size([512, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.weight: 0.23170, (torch.Size([1024, 4608]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.21962, (torch.Size([4096, 12544]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.weight: 0.21451, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.weight: 0.21315, (torch.Size([512, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.weight: 0.21019, (torch.Size([512, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.weight: 0.20859, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.weight: 0.20676, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.weight: 0.20334, (torch.Size([512, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.weight: 0.20012, (torch.Size([512, 512]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.weight: 0.19412, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,757 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.weight: 0.18568, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.weight: 0.18141, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.weight: 0.16685, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.weight: 0.16602, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.weight: 0.16123, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.weight: 0.15923, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.weight: 0.14917, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.13289, (torch.Size([4096, 4096]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.weight  : 0.12936, (torch.Size([51, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.weight: 0.12121, (torch.Size([512, 4224]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.weight: 0.11569, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.weight: 0.10657, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.weight: 0.09562, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.weight: 0.08962, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.weight: 0.08797, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.weight: 0.08553, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.weight: 0.08509, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.08482, (torch.Size([256, 1024, 3, 3]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.weight: 0.08033, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.weight: 0.08030, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.weight: 0.08006, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.06762, (torch.Size([256, 128, 3, 3]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.bias: 0.06267, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.weight: 0.06095, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.weight: 0.05995, (torch.Size([512, 2048, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.weight: 0.05590, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.weight: 0.05458, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_x.bias: 0.05328, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.bias: 0.04998, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.weight: 0.04978, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_obj_visual.bias: 0.04963, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.fc.bias: 0.04404, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.weight: 0.04301, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.fc.weight: 0.04115, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion2.dense_y.bias: 0.04102, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.weight: 0.03820, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.out_obj.bias: 0.03797, (torch.Size([151]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.weight  : 0.03579, (torch.Size([51, 4096]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03539, (torch.Size([128, 2, 7, 7]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.weight      : 0.03314, (torch.Size([4096, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.weight: 0.03278, (torch.Size([2048, 512, 1]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_vs.weight: 0.03252, (torch.Size([512, 512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_vs.bias: 0.03076, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.weight: 0.02970, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.layer_norm.bias: 0.02954, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.bias: 0.02732, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.bias: 0.02595, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_2.bias: 0.02519, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.bias: 0.02480, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.layer_norm.weight: 0.02468, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.layer_norm.weight: 0.02407, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.bias: 0.02298, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.bias: 0.02288, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc7.bias : 0.02277, (torch.Size([4096]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.bias: 0.02249, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_2.bias: 0.02213, (torch.Size([512]))
2024-05-13 21:08:00,758 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_x.bias: 0.02207, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fusion1.dense_y.bias: 0.02202, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.layer_norm.weight: 0.02202, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.fc.bias: 0.02190, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.layer_norm.weight: 0.02176, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_2.bias: 0.02150, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.weight: 0.02141, (torch.Size([512, 512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.layer_norm.weight: 0.02131, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.weight: 0.02101, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.layer_norm.weight: 0.02068, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.layer_norm.bias: 0.02067, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.weight: 0.02064, (torch.Size([512, 512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_2.bias: 0.01927, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.fc.bias: 0.01892, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.fc.bias: 0.01832, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_vs.bias: 0.01541, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_vs.bias: 0.01492, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_vs.bias: 0.01399, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.fuse_pos_union.bias: 0.01082, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.lin_edge_visual1.bias: 0.01049, (torch.Size([1024]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.box_feature_extractor.fc6.bias : 0.00941, (torch.Size([4096]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.pos_ffn.w_1.bias: 0.00870, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.pos_ffn.w_1.bias: 0.00859, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.pos_ffn.w_1.bias: 0.00809, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.pos_ffn.w_1.bias: 0.00782, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00667, (torch.Size([128]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.weight: 0.00608, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.layer_norm.bias: 0.00579, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.rel_compress.bias    : 0.00576, (torch.Size([51]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.ctx_compress.bias    : 0.00576, (torch.Size([51]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.weight: 0.00565, (torch.Size([128, 64]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.weight: 0.00535, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_2.bias: 0.00532, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.weight: 0.00515, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.layer_norm.bias: 0.00510, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.layer_norm.bias: 0.00498, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.weight: 0.00494, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_qs.bias: 0.00484, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_2.bias: 0.00469, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.layer_norm.bias: 0.00468, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_qs.bias: 0.00443, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.fc.bias: 0.00442, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_qs.bias: 0.00422, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_qs.bias: 0.00411, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.weight: 0.00399, (torch.Size([64, 21]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.bias: 0.00386, (torch.Size([128]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.3.weight: 0.00360, (torch.Size([128, 32]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_vs.bias: 0.00336, (torch.Size([512]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00245, (torch.Size([4096]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00205, (torch.Size([128]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.weight: 0.00204, (torch.Size([32, 9]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.pos_ffn.w_1.bias: 0.00197, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.post_cat.bias        : 0.00178, (torch.Size([4096]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00172, (torch.Size([256]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.pos_ffn.w_1.bias: 0.00166, (torch.Size([2048]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00161, (torch.Size([256]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.bbox_embed.0.bias: 0.00154, (torch.Size([32]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00115, (torch.Size([256]))
2024-05-13 21:08:00,759 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00104, (torch.Size([4096]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.3.bias: 0.00089, (torch.Size([128]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00088, (torch.Size([256]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00085, (torch.Size([128]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_qs.bias: 0.00079, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.rel_bbox.0.bias: 0.00051, (torch.Size([64]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.weight: 0.00009, (torch.Size([512, 512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.weight: 0.00008, (torch.Size([512, 512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_qs.bias: 0.00005, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.3.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.2.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_obj.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.1.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: roi_heads.relation.predictor.context_layer.context_edge.layer_stack.0.slf_attn.w_ks.bias: 0.00000, (torch.Size([512]))
2024-05-13 21:08:00,760 maskrcnn_benchmark INFO: -------------------------------
2024-05-13 21:08:00,761 maskrcnn_benchmark INFO: eta: 0:00:00  iter: 16000  loss: 0.5844 (0.9054)  loss_rel: 0.1219 (0.1349)  loss_refine_obj: 0.4633 (0.7706)  time: 1.1095 (1.0212)  data: 0.1670 (0.1225)  lr: 0.001600  max mem: 11247
2024-05-13 21:08:00,763 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./checkpoints/Predictor000-sgcls/model_0016000.pth
2024-05-13 21:08:02,448 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./checkpoints/Predictor000-sgcls/model_final.pth
2024-05-13 21:08:04,132 maskrcnn_benchmark INFO: Total training time: 4:32:21.912668 (1.0214 s / it)
2024-05-13 21:08:04,202 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-05-13 21:08:15,400 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2024-05-13 21:31:06,116 maskrcnn_benchmark INFO: Total run time: 0:22:50.716017 (0.051830750094828244 s / img per device, on 1 devices)
2024-05-13 21:31:06,116 maskrcnn_benchmark INFO: Model inference time: 0:20:04.990418 (0.0455641842894535 s / img per device, on 1 devices)
2024-05-13 21:45:32,325 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5940
====================================================================================================
SGG eval:     R @ 20: 0.3901;     R @ 50: 0.4259;     R @ 100: 0.4354;  for mode=sgcls, type=Recall(Main).
SGG eval:  ng-R @ 20: 0.4382;  ng-R @ 50: 0.5122;  ng-R @ 100: 0.5445;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:    zR @ 20: 0.0311;    zR @ 50: 0.0508;    zR @ 100: 0.0612;  for mode=sgcls, type=Zero Shot Recall.
SGG eval: ng-zR @ 20: 0.0362; ng-zR @ 50: 0.0849; ng-zR @ 100: 0.1264;  for mode=sgcls, type=No Graph Constraint Zero Shot Recall.
SGG eval:    mR @ 20: 0.0937;    mR @ 50: 0.1210;    mR @ 100: 0.1319;  for mode=sgcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1627) (across:0.0000) (against:0.0000) (along:0.0092) (and:0.0237) (at:0.2315) (attached to:0.0488) (behind:0.4059) (belonging to:0.0392) (between:0.0208) (carrying:0.1986) (covered in:0.1232) (covering:0.0426) (eating:0.1996) (flying in:0.0000) (for:0.0267) (from:0.0000) (growing on:0.0000) (hanging from:0.0378) (has:0.5504) (holding:0.3932) (in:0.2615) (in front of:0.1279) (laying on:0.0653) (looking at:0.0570) (lying on:0.0102) (made of:0.0000) (mounted on:0.0042) (near:0.3319) (of:0.4607) (on:0.5093) (on back of:0.0000) (over:0.0918) (painted on:0.0172) (parked on:0.1825) (part of:0.0154) (playing:0.0000) (riding:0.3120) (says:0.0000) (sitting on:0.1456) (standing on:0.0653) (to:0.0000) (under:0.2127) (using:0.1846) (walking in:0.0000) (walking on:0.1466) (watching:0.1068) (wearing:0.5204) (wears:0.0924) (with:0.1594) 
--------------------------------------------------------
SGG eval:    mR @ 20: 0.0976;    mR @ 50: 0.1287;    mR @ 100: 0.1411;  for mode=sgcls, type=Mean Micro Recall.
----------------------- Details ------------------------
(above:0.1541) (across:0.0000) (against:0.0000) (along:0.0065) (and:0.0185) (at:0.2403) (attached to:0.0382) (behind:0.4142) (belonging to:0.0511) (between:0.0185) (carrying:0.2154) (covered in:0.1327) (covering:0.0535) (eating:0.2663) (flying in:0.0000) (for:0.0424) (from:0.0000) (growing on:0.0000) (hanging from:0.0369) (has:0.5915) (holding:0.4194) (in:0.2941) (in front of:0.1309) (laying on:0.0629) (looking at:0.0573) (lying on:0.0059) (made of:0.0000) (mounted on:0.0118) (near:0.3374) (of:0.4998) (on:0.5405) (on back of:0.0000) (over:0.0916) (painted on:0.0098) (parked on:0.2363) (part of:0.0141) (playing:0.0000) (riding:0.3430) (says:0.0000) (sitting on:0.1596) (standing on:0.0674) (to:0.0000) (under:0.2117) (using:0.2036) (walking in:0.0000) (walking on:0.1543) (watching:0.1480) (wearing:0.5325) (wears:0.0861) (with:0.1579) 
--------------------------------------------------------
SGG eval: ng-mR @ 20: 0.1315; ng-mR @ 50: 0.2202; ng-mR @ 100: 0.2933;  for mode=sgcls, type=No Graph Constraint Mean Recall.
----------------------- Details ------------------------
(above:0.4620) (across:0.1111) (against:0.0806) (along:0.1300) (and:0.0976) (at:0.3912) (attached to:0.2707) (behind:0.4800) (belonging to:0.3249) (between:0.0764) (carrying:0.4008) (covered in:0.3583) (covering:0.1764) (eating:0.2824) (flying in:0.0000) (for:0.2046) (from:0.0000) (growing on:0.0828) (hanging from:0.2839) (has:0.6044) (holding:0.4558) (in:0.4701) (in front of:0.3289) (laying on:0.4164) (looking at:0.2604) (lying on:0.3497) (made of:0.0000) (mounted on:0.1642) (near:0.4824) (of:0.5782) (on:0.5726) (on back of:0.1619) (over:0.2718) (painted on:0.1585) (parked on:0.6389) (part of:0.1852) (playing:0.0000) (riding:0.4785) (says:0.0000) (sitting on:0.3977) (standing on:0.3557) (to:0.2643) (under:0.3804) (using:0.3379) (walking in:0.1197) (walking on:0.4254) (watching:0.1474) (wearing:0.5233) (wears:0.4910) (with:0.4325) 
--------------------------------------------------------
SGG eval: zs-mR @ 20: 0.0093; zs-mR @ 50: 0.0173; zs-mR @ 100: 0.0207;  for mode=sgcls, type=Zero-Shot Mean Recall.
----------------------- Details ------------------------
(above:0.0619) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.1114) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0294) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.1022) (holding:0.0596) (in:0.0749) (in front of:0.0338) (laying on:0.0417) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1234) (of:0.0251) (on:0.1204) (on back of:0.0000) (over:0.0153) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0205) (standing on:0.0000) (to:0.0000) (under:0.0668) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0244) (wearing:0.0732) (wears:0.0000) (with:0.0505) 
--------------------------------------------------------
SGG eval:     A @ 20: 0.3057;     A @ 50: 0.3059;     A @ 100: 0.3059;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

